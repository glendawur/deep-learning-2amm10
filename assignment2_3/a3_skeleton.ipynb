{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bd8459f1",
      "metadata": {
        "id": "bd8459f1"
      },
      "source": [
        "# Group Number: 32\n",
        "\n",
        "# Student 1: Ryan Meghoe\n",
        "\n",
        "# Student 2: Nikita Jain\n",
        "\n",
        "# Student 3: Andrei Rykov"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca987ad",
      "metadata": {},
      "source": [
        "# Downloading Data and Preliminaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7d0580a5",
      "metadata": {
        "id": "7d0580a5"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import requests\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8ce00edc",
      "metadata": {
        "id": "8ce00edc"
      },
      "outputs": [],
      "source": [
        "def load_zip(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    zipf = ZipFile(io.BytesIO(response.content))\n",
        "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
        "\n",
        "def load_pickle(zipfile, fn):\n",
        "    return pickle.load(io.BytesIO(zipfile[fn]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bb77a4be",
      "metadata": {
        "id": "bb77a4be"
      },
      "outputs": [],
      "source": [
        "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/cwqGaS22KXgnXtg/download')\n",
        "\n",
        "    \n",
        "\"\"\"\n",
        "simulation_{train, valid, test} is stored as a list of simulations. \n",
        "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
        "\"\"\"\n",
        "simulation_train = load_pickle(data, 'data/train/simulation.pickle')  # 3.1 + 3.2\n",
        "simulation_valid = load_pickle(data, 'data/valid/simulation.pickle')  # 3.1 + 3.2\n",
        "simulation_test = load_pickle(data, 'data/test/simulation.pickle')  # 3.1 + 3.2\n",
        "\n",
        "\"\"\"\n",
        "charges_{train, valid, test} is stored as a list of simulation-charges. \n",
        "These charges are stored as numpy arrays of size (3,): One value for each charge.\n",
        "\"\"\"\n",
        "charges_train = load_pickle(data, 'data/train/charges.pickle')  # 3.1\n",
        "charges_valid = load_pickle(data, 'data/valid/charges.pickle')  # 3.1\n",
        "charges_test = load_pickle(data, 'data/test/charges.pickle')  # 3.1\n",
        "\n",
        "\"\"\"\n",
        "simulation_continued_{train, valid, test} is stored as a list of simulations. \n",
        "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
        "\"\"\"\n",
        "simulation_continued_train = load_pickle(data, 'data/train/simulation_continued.pickle')  # 3.2\n",
        "simulation_continued_valid = load_pickle(data, 'data/valid/simulation_continued.pickle')  # 3.2\n",
        "simulation_continued_test = load_pickle(data, 'data/test/simulation_continued.pickle')  # 3.2\n",
        "\n",
        "\"\"\"\n",
        "Note that the indices are shared throughout the different lists, e.g., for the 4th training simulation:\n",
        "simulation_train[3] contains its initial simulation\n",
        "charges_train[3] contains the charges associated with the simulation\n",
        "simulation_continued_train[3] contains the continuation of the simulation \n",
        "                --> simulation_continued_train[3][0] is the state after simulation_train[3][-1]\n",
        "\"\"\"\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "10a3438a",
      "metadata": {
        "id": "10a3438a",
        "outputId": "3650d27b-c7e1-4650-c81b-b2b6ebcd8f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overview of no. datapoints:\n",
            "\n",
            "Task 3.1:\n",
            "800 train, 100 validation, 100 test simulations\n",
            "800 train, 100 validation, 100 test charge pairs\n",
            "\n",
            "Task 3.2:\n",
            "Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations\n",
            "We cut simulation_train down to the first 150 samples in simulation_train_task32\n",
            "150 train, 100 validation, 100 test simulations\n",
            "150 train, 100 validation, 100 test continuations\n",
            "\n",
            "For task 3.1, use:\n",
            "simulation_train + charges_train\n",
            "simulation_valid + charges_valid\n",
            "simulation_test + charges_test\n",
            "\n",
            "For task 3.2, use:\n",
            "simulation_train_task32 + simulation_continued_train\n",
            "simulation_valid + simulation_continued_valid\n",
            "simulation_test + simulation_continued_test\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Overview of no. datapoints:\\n')\n",
        "\n",
        "print('Task 3.1:')\n",
        "print(f'{len(simulation_train)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
        "print(f'{len(charges_train)} train, {len(charges_valid)} validation, {len(charges_test)} test charge pairs')\n",
        "print()\n",
        "\n",
        "print('Task 3.2:')\n",
        "print('Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations')\n",
        "print('We cut simulation_train down to the first 150 samples in simulation_train_task32')\n",
        "simulation_train_task32 = simulation_train[:150]\n",
        "print(f'{len(simulation_train_task32)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
        "print(f'{len(simulation_continued_train)} train, {len(simulation_continued_valid)} validation, {len(simulation_continued_test)} test continuations')\n",
        "\n",
        "print(f\"\"\"\n",
        "For task 3.1, use:\n",
        "{chr(10).join([\"simulation_{} + charges_{}\".format(t, t) for t in [\"train\", \"valid\", \"test\"]])}\n",
        "\n",
        "For task 3.2, use:\n",
        "{chr(10).join([\"simulation_{} + simulation_continued_{}\".format(*((t[0], t[1]) if isinstance(t, tuple) else (t, t))) for t in [(\"train_task32\", \"train\"), \"valid\", \"test\"]])}\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3cfafdb3",
      "metadata": {
        "id": "3cfafdb3",
        "outputId": "42ffce38-a6f3-4219-c759-ee0b42d6c44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Print some shapes:\n",
            "\n",
            "simulation_train[0].shape: (103, 2) -> (t, 2), (x, y) at every t)\n",
            "charges_train[0].shape: (3,) -> charges for the simulation\n",
            "simulation_continued_train[0].shape: (54, 2) -> (t, 2), (x, y) at every t)\n",
            "----\n",
            "\n",
            "simulation_train[1].shape: (97, 2) -> (t, 2), (x, y) at every t)\n",
            "charges_train[1].shape: (3,) -> charges for the simulation\n",
            "simulation_continued_train[1].shape: (45, 2) -> (t, 2), (x, y) at every t)\n",
            "----\n",
            "\n",
            "simulation_train[2].shape: (99, 2) -> (t, 2), (x, y) at every t)\n",
            "charges_train[2].shape: (3,) -> charges for the simulation\n",
            "simulation_continued_train[2].shape: (47, 2) -> (t, 2), (x, y) at every t)\n",
            "----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Print some shapes:\\n')\n",
        "for i in range(3):\n",
        "    print('simulation_train[{}].shape:'.format(i), simulation_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
        "    print('charges_train[{}].shape:'.format(i), charges_train[i].shape, '-> charges for the simulation')\n",
        "    print('simulation_continued_train[{}].shape:'.format(i), simulation_continued_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
        "    print('----\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f9106543",
      "metadata": {
        "id": "f9106543"
      },
      "outputs": [],
      "source": [
        "def plot_example(x, x_gt=None, x_pred=None, fn=None):\n",
        "    charge_locations = np.array([[-1.53846154, -1.53846154],\n",
        "                                 [ 1.53846154, -1.53846154],\n",
        "                                 [ 0.        ,  1.53846154]])  # charge locations are fixed\n",
        "    fig = plt.figure()\n",
        "    axes = plt.gca()\n",
        "    axes.set_xlim([-5., 5.])\n",
        "    axes.set_ylim([-5., 5.])\n",
        "    cmap = matplotlib.cm.get_cmap('tab20')\n",
        "    plt.plot(x[:, 0], x[:, 1], color=cmap(0))\n",
        "    plt.plot(x[0, 0], x[0, 1], 'd', color=cmap(1))\n",
        "    fig.set_size_inches(5, 5)\n",
        "    for charge in charge_locations:\n",
        "        plt.plot(charge[0], charge[1], 'd', color='black')\n",
        "    if x_gt is not None:\n",
        "        plt.plot(x_gt[:, 0], x_gt[:, 1], color='red', linewidth=.5)\n",
        "    if x_pred is not None:\n",
        "        plt.plot(x_pred[:, 0], x_pred[:, 1], color='green', linestyle='--')\n",
        "    if fn is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d28681a6",
      "metadata": {
        "id": "d28681a6",
        "outputId": "c34406d9-7732-4d6b-a092-d32025eaa83a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Charges are [-0.16157069 -0.9385916  -0.53660326]\n"
          ]
        }
      ],
      "source": [
        "test_idx = np.random.randint(150)\n",
        "plot_example(simulation_train[test_idx], simulation_continued_train[test_idx])\n",
        "print(f'Charges are {charges_train[test_idx]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c1ddabe",
      "metadata": {
        "id": "4c1ddabe"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bd9df856",
      "metadata": {
        "id": "bd9df856"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as f\n",
        "import torch\n",
        "\n",
        "simulation_train = torch.cat(list(map(lambda x: f.pad(torch.Tensor(x), pad=(0, 0, 110 - x.shape[0], 0)).unsqueeze(0), simulation_train)))\n",
        "simulation_valid = torch.cat(list(map(lambda x: f.pad(torch.Tensor(x), pad=(0, 0, 110 - x.shape[0], 0)).unsqueeze(0), simulation_valid)))\n",
        "simulation_test = torch.cat(list(map(lambda x: f.pad(torch.Tensor(x), pad=(0, 0, 110 - x.shape[0], 0)).unsqueeze(0), simulation_test)))\n",
        "\n",
        "\n",
        "simulation_continued_train = torch.cat(list(map(lambda x: f.pad(torch.Tensor(x), pad=(0, 0, 0, 60 - x.shape[0])).unsqueeze(0), simulation_continued_train)))\n",
        "simulation_continued_valid = torch.cat(list(map(lambda x: f.pad(torch.Tensor(x), pad=(0, 0, 0, 60 - x.shape[0])).unsqueeze(0), simulation_continued_valid)))\n",
        "simulation_continued_test = torch.cat(list(map(lambda x: f.pad(torch.Tensor(x), pad=(0, 0, 0, 60 - x.shape[0])).unsqueeze(0), simulation_continued_test)))\n",
        "\n",
        "\n",
        "charges_train = torch.cat(list(map(lambda x: torch.Tensor(x).unsqueeze(0), charges_train)))\n",
        "charges_valid = torch.cat(list(map(lambda x: torch.Tensor(x).unsqueeze(0), charges_valid)))\n",
        "charges_test = torch.cat(list(map(lambda x: torch.Tensor(x).unsqueeze(0), charges_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5b0c3264",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([150, 60, 2])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simulation_continued_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e872c309",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([800, 110, 2])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simulation_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7dd9b7c1",
      "metadata": {
        "id": "7dd9b7c1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "lengths_train = torch.Tensor(list(map(lambda x: x.shape[0], simulation_continued_train))).unsqueeze(-1)\n",
        "lengths_valid = torch.Tensor(list(map(lambda x: x.shape[0], simulation_continued_valid))).unsqueeze(-1)\n",
        "lengths_test = torch.Tensor(list(map(lambda x: x.shape[0], simulation_continued_test))).unsqueeze(-1)\n",
        "\n",
        "train_dataset_31 = TensorDataset(simulation_train, charges_train)\n",
        "valid_dataset_31 = TensorDataset(simulation_valid, charges_valid)\n",
        "test_dataset_31 = TensorDataset(simulation_test, charges_test)\n",
        "\n",
        "train_dataset_32 = TensorDataset(simulation_train[:simulation_continued_train.shape[0]], simulation_continued_train, lengths_train)\n",
        "valid_dataset_32 = TensorDataset(simulation_valid[:simulation_continued_valid.shape[0]], simulation_continued_valid, lengths_valid)\n",
        "test_dataset_32 = TensorDataset(simulation_test[:simulation_continued_test.shape[0]], simulation_continued_test, lengths_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4ec1e03a",
      "metadata": {
        "id": "4ec1e03a"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader_31 = DataLoader(train_dataset_31, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader_31 = DataLoader(valid_dataset_31, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader_31 = DataLoader(test_dataset_31, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_dataloader_32 = DataLoader(train_dataset_32, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader_32 = DataLoader(valid_dataset_32, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader_32 = DataLoader(test_dataset_32, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883762b1",
      "metadata": {
        "id": "883762b1"
      },
      "source": [
        "# Task 3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc8853f6",
      "metadata": {
        "id": "cc8853f6"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "8794a0cf",
      "metadata": {
        "id": "8794a0cf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, coord_shape, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        ### Your code here ###\n",
        "        #self.embedding = nn.Sequential(nn.Linear(coord_shape, emb_dim),\n",
        "        #                               nn.Dropout(droupout))\n",
        "        \n",
        "        self.rnn = nn.LSTM(coord_shape, hid_dim, n_layers, dropout = dropout, batch_first = True)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        \n",
        "        _, (hidden, cell) = self.rnn(input)\n",
        "\n",
        "        return hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d62b5aa6",
      "metadata": {
        "id": "d62b5aa6"
      },
      "outputs": [],
      "source": [
        "class SequenceToCharge(nn.Module):\n",
        "    def __init__(self, coord_shape, emb_dim, hid_dim, n_layers, dropout,\n",
        "                 output_shape):\n",
        "        super(SequenceToCharge, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(coord_shape, emb_dim, hid_dim, n_layers, dropout)\n",
        "\n",
        "        self.dense = nn.Sequential(nn.Linear(hid_dim, output_shape)\n",
        "                                #, nn.ReLU(),\n",
        "                                #  nn.Linear(hidden, output_shape)  \n",
        "                                  )\n",
        "\n",
        "    def forward(self, particle_trajectory):\n",
        "        hidden, _ = self.encoder(particle_trajectory)\n",
        "        output = self.dense(hidden[-1])\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e443b7f",
      "metadata": {
        "id": "0e443b7f"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "58348edd",
      "metadata": {
        "id": "58348edd"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "class Trainer31():\n",
        "    def __init__(self,\n",
        "                 model: torch.nn.Module,\n",
        "                 device: torch.device,\n",
        "                 criterion: torch.nn.Module,\n",
        "                 optimizer: torch.optim.Optimizer,\n",
        "                 training_DataLoader: torch.utils.data.Dataset,\n",
        "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
        "                 testing_DataLoader: torch.utils.data.Dataset ,\n",
        "                 epochs: int\n",
        "                 ):\n",
        "        \n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.training_DataLoader = training_DataLoader\n",
        "        self.validation_DataLoader = validation_DataLoader\n",
        "        self.testing_DataLoader = testing_DataLoader\n",
        "        self.device = device\n",
        "        self.epochs = epochs\n",
        "\n",
        "\n",
        "    def run_trainer(self):\n",
        "\n",
        "        epoch_train_losses = []\n",
        "        epoch_val_losses = []\n",
        "\n",
        "        for epoch in tqdm(range(self.epochs)):\n",
        "                 \n",
        "\n",
        "            self.model.train()  # train mode\n",
        "\n",
        "            train_losses=[]\n",
        "            \n",
        "            correct = 0\n",
        "            length = 0\n",
        "            for x, y in self.training_DataLoader:\n",
        "\n",
        "                sequence, charges = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
        "\n",
        "                self.optimizer.zero_grad()  # zerograd the parameters\n",
        "\n",
        "                loss = 0\n",
        "                out = self.model(sequence)  # one forward pass\n",
        "\n",
        "                loss += self.criterion(out, charges)  # calculate loss\n",
        "                \n",
        "                loss_value = loss.item()\n",
        "                train_losses.append(loss_value)\n",
        "                 \n",
        "                loss.backward()  # one backward pass\n",
        "                self.optimizer.step()  # update the parameters\n",
        "            \n",
        "            epoch_train_losses.append(np.mean(train_losses))\n",
        "            self.model.eval()  # evaluation mode\n",
        "            valid_losses = []  # accumulate the losses here\n",
        "\n",
        "            correct = 0\n",
        "            length = 0\n",
        "            for x,  y in self.validation_DataLoader:\n",
        "\n",
        "                sequence, charges = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    loss = 0\n",
        "                    \n",
        "                    out = self.model(sequence)  # one forward pass\n",
        "                    loss += self.criterion(out, charges)  # calculate loss\n",
        "                 \n",
        "                    loss_value = loss.item()\n",
        "                    valid_losses.append(loss_value)\n",
        "\n",
        "            epoch_val_losses.append(np.mean(valid_losses))\n",
        "                \n",
        "            # print the results\n",
        "            print(\n",
        "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
        "                end=' '\n",
        "            )\n",
        "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
        "            print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')\n",
        "\n",
        "        return epoch_train_losses, epoch_val_losses\n",
        "        \n",
        "    def evaluate(self):\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loss = []\n",
        "            length = 0\n",
        "            for x,y in self.testing_DataLoader:\n",
        "                \n",
        "                sequence, charges = x.float().to(self.device), y.float().to(self.device)\n",
        "                out = self.model(sequence)\n",
        "                loss.append(self.criterion(out, charges))\n",
        "                \n",
        "        print(f'Error: {np.mean(loss):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176b3ea3",
      "metadata": {
        "id": "176b3ea3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "da139d5b",
      "metadata": {
        "id": "da139d5b"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ebed03ba",
      "metadata": {
        "id": "ebed03ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 1/20 [00:00<00:09,  1.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 01/20 LOSS: 0.1838 VAL-LOSS: 0.1047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 2/20 [00:00<00:08,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 02/20 LOSS: 0.0867 VAL-LOSS: 0.0916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 3/20 [00:01<00:07,  2.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 03/20 LOSS: 0.0766 VAL-LOSS: 0.0850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 4/20 [00:01<00:07,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 04/20 LOSS: 0.0753 VAL-LOSS: 0.0873\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 5/20 [00:02<00:06,  2.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 05/20 LOSS: 0.0735 VAL-LOSS: 0.0845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 6/20 [00:02<00:06,  2.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 06/20 LOSS: 0.0733 VAL-LOSS: 0.0856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 7/20 [00:03<00:06,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 07/20 LOSS: 0.0723 VAL-LOSS: 0.0834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 8/20 [00:03<00:05,  2.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 08/20 LOSS: 0.0716 VAL-LOSS: 0.0822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 9/20 [00:04<00:04,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 09/20 LOSS: 0.0716 VAL-LOSS: 0.0831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 10/20 [00:04<00:04,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 10/20 LOSS: 0.0698 VAL-LOSS: 0.0795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 11/20 [00:04<00:03,  2.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 11/20 LOSS: 0.0672 VAL-LOSS: 0.0762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 12/20 [00:05<00:03,  2.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 12/20 LOSS: 0.0634 VAL-LOSS: 0.0756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 13/20 [00:05<00:02,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 13/20 LOSS: 0.0693 VAL-LOSS: 0.0732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 14/20 [00:06<00:02,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 14/20 LOSS: 0.0668 VAL-LOSS: 0.0747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 15/20 [00:06<00:02,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 15/20 LOSS: 0.0618 VAL-LOSS: 0.0733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 16/20 [00:07<00:01,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 16/20 LOSS: 0.0625 VAL-LOSS: 0.0675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 17/20 [00:07<00:01,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 17/20 LOSS: 0.0588 VAL-LOSS: 0.0783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 18/20 [00:08<00:00,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 18/20 LOSS: 0.0636 VAL-LOSS: 0.0714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 19/20 [00:08<00:00,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 19/20 LOSS: 0.0558 VAL-LOSS: 0.0628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 20/20 LOSS: 0.0506 VAL-LOSS: 0.0583\n",
            "Error: 0.0550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "else:\n",
        "        device=torch.device('cpu')\n",
        "\n",
        "model = SequenceToCharge(coord_shape = 2, emb_dim = 8, hid_dim = 16, n_layers = 1, dropout = 0.5, \n",
        "                        output_shape = 3).to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "TrainingProcedure = Trainer31(model, \n",
        "                                device, \n",
        "                                criterion, \n",
        "                                optimizer,\n",
        "                                train_dataloader_31,\n",
        "                                valid_dataloader_31,\n",
        "                                test_dataloader_31,\n",
        "                                epochs = 20)\n",
        "\n",
        "train_loss, val_loss = TrainingProcedure.run_trainer()\n",
        "TrainingProcedure.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17af7ec3",
      "metadata": {
        "id": "17af7ec3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a3422e",
      "metadata": {
        "id": "43a3422e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9a59808b",
      "metadata": {
        "id": "9a59808b"
      },
      "source": [
        "# Task 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867aabb3",
      "metadata": {
        "id": "867aabb3"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "36fe2739",
      "metadata": {
        "id": "36fe2739"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_shape, hid_dim, n_layers, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.rnn = nn.LSTM(input_shape, hid_dim, n_layers, dropout=dropout, batch_first = True)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        output, (hidden, cell) = self.rnn(input, (hidden, cell))\n",
        "\n",
        "        return output, (hidden, cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "f80b1ca2",
      "metadata": {
        "id": "f80b1ca2"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "\n",
        "class Seq2SeqARG(nn.Module):\n",
        "    def __init__(self, coord_shape, emb_dim, hid_dim, n_layers, dropout, device = torch.device('cpu')):\n",
        "        super(Seq2SeqARG, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.encoder = Encoder(coord_shape, emb_dim, hid_dim, n_layers, dropout)\n",
        "\n",
        "        self.decoder = Decoder(input_shape=coord_shape, hid_dim=hid_dim, n_layers=n_layers, dropout=dropout)\n",
        "\n",
        "        self.dense = nn.Sequential(nn.Linear(hid_dim, coord_shape))\n",
        "\n",
        "    def forward(self, particle_trajectory, target_trajectory, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        hidden, cell = self.encoder(particle_trajectory)\n",
        "        \n",
        "        hidden = hidden[:,0,:]\n",
        "        cell = cell[:,0,:]\n",
        "\n",
        "        predicted_target = torch.zeros((target_trajectory.shape)).to(self.device)\n",
        "\n",
        "        input = particle_trajectory[:,-1,:]\n",
        "        for t in range(0, target_trajectory.shape[1]):\n",
        "            \n",
        "            output, (hidden, cell) = self.decoder(input, hidden, cell)\n",
        "            # output = (batch_size, 1, hid_dim)\n",
        "\n",
        "            predicted_target[:,t] = self.dense(output)\n",
        "\n",
        "            # ground truth usage\n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = np.random.rand(1)[0] > teacher_forcing_ratio\n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = target_trajectory[:,t]\n",
        "\n",
        "            input = predicted_target[:,t ] if teacher_force else top1\n",
        "        \n",
        "        return predicted_target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826fae3f",
      "metadata": {
        "id": "826fae3f"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "5a92c60d",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Trainer32():\n",
        "    def __init__(self,\n",
        "                 model: torch.nn.Module,\n",
        "                 device: torch.device,\n",
        "                 criterion: torch.nn.Module,\n",
        "                 optimizer: torch.optim.Optimizer,\n",
        "                 training_DataLoader: torch.utils.data.Dataset,\n",
        "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
        "                 testing_DataLoader: torch.utils.data.Dataset ,\n",
        "                 epochs: int\n",
        "                 ):\n",
        "        \n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.training_DataLoader = training_DataLoader\n",
        "        self.validation_DataLoader = validation_DataLoader\n",
        "        self.testing_DataLoader = testing_DataLoader\n",
        "        self.device = device\n",
        "        self.epochs = epochs\n",
        "\n",
        "\n",
        "    def run_trainer(self):\n",
        "\n",
        "        epoch_train_losses = []\n",
        "        epoch_val_losses = []\n",
        "\n",
        "        for epoch in tqdm(range(self.epochs)):\n",
        "                 \n",
        "\n",
        "            self.model.train()  # train mode\n",
        "\n",
        "            train_losses=[]\n",
        "            \n",
        "            correct = 0\n",
        "            length = 0\n",
        "            for x, y, z in self.training_DataLoader:\n",
        "\n",
        "                x_sequence, y_sequence, lengths = x.float().to(self.device), y.float().to(self.device), z.float().to(self.device) # send to device (GPU or CPU)\n",
        "                \n",
        "\n",
        "                self.optimizer.zero_grad()  # zerograd the parameters\n",
        "\n",
        "                loss = 0\n",
        "                # out - (batch_size, sequence_length, coordinates)\n",
        "                out = self.model(x_sequence, y_sequence)  # one forward pass\n",
        "\n",
        "                #for pred,actual,seq_len in zip(out, y_sequence, lengths):\n",
        "\n",
        "                #    loss += self.criterion(pred[:seq_len], actual[:seq_len])  # calculate loss\n",
        "\n",
        "                mask = (torch.arange(60)[None, :] < lengths.view(-1)[:, None]).unsqueeze(-1)\n",
        "                loss += torch.mean(torch.sum((out*mask - y_sequence).pow(2), dim=[1,2]) / lengths.view(-1))\n",
        "                \n",
        "                loss_value = loss.item()\n",
        "                train_losses.append(loss_value)\n",
        "                 \n",
        "                loss.backward()  # one backward pass\n",
        "                self.optimizer.step()  # update the parameters\n",
        "            \n",
        "            epoch_train_losses.append(np.mean(train_losses))\n",
        "            self.model.eval()  # evaluation mode\n",
        "            valid_losses = []  # accumulate the losses here\n",
        "\n",
        "            correct = 0\n",
        "            length = 0\n",
        "            for x, y, z in self.validation_DataLoader:\n",
        "\n",
        "                x_sequence, y_sequence, lengths = x.float().to(self.device), y.float().to(self.device), z.float().to(self.device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    loss = 0\n",
        "                    \n",
        "                    out = self.model(x_sequence, y_sequence)  # one forward pass\n",
        "                    \n",
        "                    mask = (torch.arange(60)[None, :] < lengths.view(-1)[:, None]).unsqueeze(-1)\n",
        "                    loss += torch.mean(torch.sum((out*mask - y_sequence).pow(2), dim=[1,2]) / lengths.view(-1) ) # calculate loss\n",
        "                 \n",
        "                    loss_value = loss.item()\n",
        "                    valid_losses.append(loss_value)\n",
        "\n",
        "            epoch_val_losses.append(np.mean(valid_losses))\n",
        "                \n",
        "            # print the results\n",
        "            print(\n",
        "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
        "                end=' '\n",
        "            )\n",
        "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
        "            print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')\n",
        "\n",
        "        return epoch_train_losses, epoch_val_losses\n",
        "        \n",
        "    def evaluate(self):\n",
        "\n",
        "        self.model.eval()\n",
        "        times = [0.5, 1, 1.5]\n",
        "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loss = []\n",
        "            length = 0\n",
        "            for x,y,z in self.testing_DataLoader:\n",
        "                \n",
        "                x_sequence, y_sequence, lengths = x.float().to(self.device), y.float().to(self.device), z.float().to(self.device)\n",
        "                out = self.model(x_sequence, y_sequence)\n",
        "                loss_batch = 0\n",
        "                mask = (torch.arange(60)[None, :] < lengths.view(-1)[:, None]).unsqueeze(-1)\n",
        "                loss_batch += torch.mean(torch.sum((out*mask - y_sequence).pow(2), dim=[1,2]) / lengths.view(-1)) \n",
        "\n",
        "                loss.append(loss_batch)\n",
        "        print(f'Error: {np.mean(loss):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87278a2",
      "metadata": {
        "id": "c87278a2"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "2cbb6137",
      "metadata": {
        "id": "2cbb6137"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\onii-chan\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  5%|▌         | 1/20 [00:01<00:36,  1.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 01/20 LOSS: 4.0825 VAL-LOSS: 4.4322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 2/20 [00:03<00:33,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 02/20 LOSS: 3.8802 VAL-LOSS: 4.2778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 3/20 [00:05<00:30,  1.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 03/20 LOSS: 3.8492 VAL-LOSS: 4.0551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 4/20 [00:07<00:28,  1.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 04/20 LOSS: 3.5875 VAL-LOSS: 4.0937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 5/20 [00:08<00:26,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 05/20 LOSS: 3.6313 VAL-LOSS: 3.6563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 6/20 [00:10<00:24,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 06/20 LOSS: 3.1282 VAL-LOSS: 3.4847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 7/20 [00:12<00:22,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 07/20 LOSS: 2.6386 VAL-LOSS: 3.0876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 8/20 [00:14<00:20,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 08/20 LOSS: 2.4266 VAL-LOSS: 2.3425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 9/20 [00:15<00:19,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 09/20 LOSS: 2.0011 VAL-LOSS: 1.8586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 10/20 [00:17<00:17,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 10/20 LOSS: 1.5756 VAL-LOSS: 1.5825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 11/20 [00:19<00:15,  1.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 11/20 LOSS: 1.2529 VAL-LOSS: 1.1462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 12/20 [00:21<00:13,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 12/20 LOSS: 1.0964 VAL-LOSS: 0.9927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 13/20 [00:22<00:12,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 13/20 LOSS: 0.7519 VAL-LOSS: 0.9023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 14/20 [00:24<00:10,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 14/20 LOSS: 0.6271 VAL-LOSS: 0.8209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 15/20 [00:26<00:08,  1.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 15/20 LOSS: 0.5367 VAL-LOSS: 0.8167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 16/20 [00:28<00:07,  1.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 16/20 LOSS: 0.4847 VAL-LOSS: 0.6676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 17/20 [00:29<00:05,  1.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 17/20 LOSS: 0.4676 VAL-LOSS: 0.7321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 18/20 [00:31<00:03,  1.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 18/20 LOSS: 0.4705 VAL-LOSS: 0.6166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 19/20 [00:33<00:01,  1.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 19/20 LOSS: 0.3841 VAL-LOSS: 0.5867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:35<00:00,  1.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 20/20 LOSS: 0.4007 VAL-LOSS: 0.6593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: 0.3325\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "else:\n",
        "        device=torch.device('cpu')\n",
        "\n",
        "model = Seq2SeqARG(coord_shape = 2, emb_dim = 8, hid_dim = 16, n_layers = 1, dropout = 0.5).to(device)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "TrainingProcedure = Trainer32(model, \n",
        "                                device, \n",
        "                                criterion, \n",
        "                                optimizer,\n",
        "                                train_dataloader_32,\n",
        "                                valid_dataloader_32,\n",
        "                                test_dataloader_32,\n",
        "                                epochs = 20)\n",
        "\n",
        "train_loss, val_loss = TrainingProcedure.run_trainer()\n",
        "TrainingProcedure.evaluate()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "a3_skeleton.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
