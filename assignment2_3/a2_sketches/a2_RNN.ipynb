{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {
    "id": "d32f8d18"
   },
   "source": [
    "# Group Number:\n",
    "\n",
    "# Student 1: Ryan Meghoe\n",
    "\n",
    "# Student 2: Nikita Jain\n",
    "\n",
    "# Student 3: Andrei Rykov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {
    "id": "faec2056"
   },
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {
    "id": "7d0580a5"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc346bc",
   "metadata": {
    "id": "8fc346bc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0756591",
   "metadata": {
    "id": "b0756591"
   },
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_array(zipfile, fn):\n",
    "    return np.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb77a4be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb77a4be",
    "outputId": "e5562ffc-e8b8-43de-cd53-a1d1b8ad2da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the training data:\n",
      "\n",
      "positions: (10000, 4, 2, 5)\n",
      "velocities: (10000, 1, 2, 5)\n",
      "charges: (10000, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell loads the training, validation or test data as numpy arrays,\n",
    "with the positions, initial velocities and charge data of the particles.\n",
    "\n",
    "The position arrays are shaped as\n",
    "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
    "\n",
    "The initial velocity arrays are shaped as\n",
    "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
    "\n",
    "The charge arrays are shaped as [simulation id, particle id, 1]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
    "\n",
    "features = ['positions', 'velocities', 'charges']\n",
    "    \n",
    "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
    "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
    "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
    "\n",
    "print('Shapes of the training data:\\n')\n",
    "print(f'positions: {positions_train.shape}')\n",
    "print(f'velocities: {velocities_train.shape}')\n",
    "print(f'charges: {charges_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3ea4cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c3ea4cb",
    "outputId": "fe3f76c1-7e8c-481d-c310-610e1c438cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of retrieving data from the arrays:\n",
      "\n",
      "\n",
      "In simulation 42 of the training set, particle 3 with charge -1.0 had coordinates [ 2.05159559 -1.46130851].\n",
      "The initial velocity of this particle was [ 0.28402364 -0.24784824].\n"
     ]
    }
   ],
   "source": [
    "print('An example of retrieving data from the arrays:\\n\\n')\n",
    "\n",
    "sim_idx = 42\n",
    "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
    "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
    "particle_idx = 3  # corresponds to particle with index 3\n",
    "\n",
    "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
    "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
    "c = charges_train[sim_idx, particle_idx, 0] \n",
    "\n",
    "print(\n",
    "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a3438a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10a3438a",
    "outputId": "01d1f87c-6d4f-4c06-f2a2-b7cf5c3caf56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "10000 train, 2000 validation, 2000 test simulations\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9106543",
   "metadata": {
    "id": "f9106543"
   },
   "outputs": [],
   "source": [
    "def plot_example(pos, vel):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(pos.shape[-1]):\n",
    "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
    "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
    "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.plot([], [], 'd', color='black', label='initial position')\n",
    "    plt.plot([], [], 'x', color='black', label='final position')\n",
    "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28681a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "d28681a6",
    "outputId": "afd726bd-9de5-4118-eb22-02689717a04f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = np.random.randint(0, 10000)\n",
    "plot_example(positions_train[random_idx], velocities_train[random_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {
    "id": "059b633c"
   },
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ecb529",
   "metadata": {
    "id": "e6ecb529"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train = torch.cat((torch.tensor(positions_train[:,0,:,:]), torch.tensor(charges_train).squeeze(-1).unsqueeze(1)), dim=1)\n",
    "X_train = torch.cat((X_train, torch.tensor(velocities_train).squeeze(1)), dim=1) # shape: (simulation id, parameters (x, y, c, v_x, v_y), particle id)\n",
    "y_train = torch.tensor(positions_train[:,1:,:,:]) # shape: (simulation id, time (0.5, 1, 1.5), (x, y), particle id)\n",
    "\n",
    "X_valid = torch.cat((torch.tensor(positions_valid[:,0,:,:]), torch.tensor(charges_valid).squeeze(-1).unsqueeze(1)), dim=1)\n",
    "X_valid = torch.cat((X_valid, torch.tensor(velocities_valid).squeeze(1)), dim=1)\n",
    "y_valid = torch.tensor(positions_valid[:,1:,:,:])\n",
    "\n",
    "X_test = torch.cat((torch.tensor(positions_test[:,0,:,:]), torch.tensor(charges_test).squeeze(-1).unsqueeze(1)), dim=1)\n",
    "X_test = torch.cat((X_test, torch.tensor(velocities_test).squeeze(1)), dim=1)\n",
    "y_test = torch.tensor(positions_test[:,1:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8633eb8",
   "metadata": {
    "id": "f8633eb8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a99a32b",
   "metadata": {
    "id": "0a99a32b"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {
    "id": "18b2874d"
   },
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66774050",
   "metadata": {
    "id": "66774050"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ParticleModel(torch.nn.Module):\n",
    "    def __init__(self, device, set_size: int = 5, input_size: int = 5, \n",
    "                 fau1_out: int = 16, gamma1_out: int = 32, fau2_out: int = 64, gamma2_out: int = 64,\n",
    "                 hidden_dim: int = 32, output_shape: int = 2, horizon_length: int = 3):\n",
    "        super(ParticleModel, self).__init__()\n",
    "        # first iteration \n",
    "        # layer 1\n",
    "        # input target (x_t, y_t, c_t, v_t) + neighbour (x_n, y_n, c_n, v_n) + edge (distance(t, n)) \n",
    "        # as the result input for first layer is x + x + 1 = 2x + 1 (8 + 1 in our case)\n",
    "        self.fau_iteration1 = nn.Sequential(nn.Linear(input_size*2 + 1, fau1_out),\n",
    "                                            nn.ReLU())\n",
    "        # embeddings are calculated\n",
    "\n",
    "        # layer 2\n",
    "        # input (x_target, y_target, c_target, v_target) + embedding from layer_1\n",
    "        self.gamma_iteration1 = nn.Sequential(nn.Linear(fau1_out+input_size, gamma1_out),\n",
    "                                              nn.ReLU())\n",
    "        self.embedding_size = (set_size, gamma1_out)\n",
    "\n",
    "        # second iteration \n",
    "        # layer 3\n",
    "        # input target (embedding from layer 1) + neigbour (embedding from layer 1) + edge (distance(t, n))\n",
    "        self.fau_iteration2 = nn.Sequential(nn.Linear(gamma1_out*2 + 1, fau2_out),\n",
    "                                            nn.ReLU())\n",
    "        # embeddings are calculated\n",
    "\n",
    "        # layer 4\n",
    "        # input (x_target, y_target, c_target, v_target) + embedding from layer_3\n",
    "        self.gamma_iteration2 = nn.Sequential(nn.Linear(fau2_out + gamma1_out, gamma2_out),\n",
    "                                              nn.ReLU())\n",
    "        self.deepset_output = (set_size, gamma2_out)\n",
    "        \n",
    "\n",
    "        #####\n",
    "        # Recurrent Part\n",
    "        self.rnn = nn.LSTM(gamma2_out*set_size, hidden_dim, num_layers = 1, batch_first = True)\n",
    "        \n",
    "        # Fully connected layer after RNN output, to learn more complex relations\n",
    "        self.final = nn.Linear(hidden_dim, output_shape*set_size)\n",
    "\n",
    "        # auxiliary veriable to store the device\n",
    "        self.device = device\n",
    "        self.output_shape = output_shape\n",
    "        self.horizon_length = horizon_length\n",
    "\n",
    "    \n",
    "    def forward_iteration1(self, particle_set, distances):\n",
    "        embedding = torch.zeros((particle_set.shape[0], self.embedding_size[0], self.embedding_size[1])).to(self.device)\n",
    "        \n",
    "        for i in range(particle_set.shape[1]):\n",
    "            # concatenate the neighborhood\n",
    "            x = torch.cat([particle_set[:,i].reshape((particle_set.shape[0], 1, 5)).repeat((1, particle_set.shape[1] - 1, 1)),\n",
    "                           particle_set[:, list(set(range(particle_set.shape[1])).difference({i}))],\n",
    "                           distances[:, i, list(set(range(particle_set.shape[1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
    "                                                                                                   particle_set.shape[1]-1,1))],\n",
    "                          2).to(self.device)\n",
    "\n",
    "\n",
    "            x = self.fau_iteration1(x)\n",
    "\n",
    "            # aggregation function\n",
    "            # mean as a placeholder for now\n",
    "            x = x.mean(axis = 1)\n",
    "            # concatenate \n",
    "            x = torch.cat([particle_set[:, i].view(particle_set.shape[0], 1, -1),\n",
    "                           x.view(particle_set.shape[0], 1, -1)],\n",
    "                           dim = 2)\n",
    "            embedding[:,i] = self.gamma_iteration1(x).view(embedding[:,i].shape)\n",
    "        return embedding\n",
    "\n",
    "    def forward_iteration2(self, particle_set, distances):\n",
    "        embedding = torch.zeros((particle_set.shape[0], self.deepset_output[0], self.deepset_output[1])).to(self.device)\n",
    "        for i in range(particle_set.shape[1]):\n",
    "            # concatenate the neighborhood\n",
    "            x = torch.cat([particle_set[:,i].reshape((particle_set.shape[0], 1, particle_set.shape[2])).repeat((1, particle_set.shape[1] - 1, 1)),\n",
    "                           particle_set[:, list(set(range(particle_set.shape[1])).difference({i}))],\n",
    "                           distances[:, i, list(set(range(particle_set.shape[1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
    "                                                                                                   particle_set.shape[1]-1,1))],\n",
    "                          2).to(self.device)\n",
    "\n",
    "            x = self.fau_iteration2(x)\n",
    "\n",
    "            # aggregation function\n",
    "            # mean as a placeholder for now\n",
    "            x = x.mean(axis = 1)\n",
    "\n",
    "            \n",
    "            # concatenate \n",
    "            x = torch.cat([particle_set[:, i].view(particle_set.shape[0], 1, -1),\n",
    "                           x.view(particle_set.shape[0], 1, -1)],\n",
    "                           dim = 2)    \n",
    "\n",
    "            embedding[:,i] = self.gamma_iteration2(x).view(embedding[:,i].shape)\n",
    "        return embedding\n",
    "\n",
    "    def forward(self, particle_set):\n",
    "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set[:,:2,:].swapaxes(1,2)], dim=0).to(self.device)\n",
    "        p1 = self.forward_iteration1(particle_set = particle_set, distances = distances)\n",
    "        out = self.forward_iteration2(particle_set=p1, distances=distances).reshape((particle_set.shape[0], 1, -1))\n",
    "        \n",
    "        zeros = torch.zeros((particle_set.shape[0], self.horizon_length, self.deepset_output[0]*self.deepset_output[1])).to(self.device) \n",
    "        #(batch_size, 1, embedding_dim)\n",
    "        rnn_input = torch.cat([out, zeros], dim=1)\n",
    "        \n",
    "        \n",
    "        # Input: (Batch size, L (sequence length), input_shape)\n",
    "        # rnn_output: (Batch size, L (sequence length), output_shape)\n",
    "        rnn_output, rnn_state = self.rnn(rnn_input)\n",
    "\n",
    "        #print(f'{rnn_output[:,1:,:].shape}')\n",
    "        # To further process, put the data through a dense layer\n",
    "        output = self.final(rnn_output[:,1:,:])\n",
    "        \n",
    "        #print(f'{output.shape}')\n",
    "        # (batch_size, horizon_length, output_shape, set_size)\n",
    "        return output.view((output.shape[0], self.horizon_length, self.output_shape, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {
    "id": "dea70d73"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e95af5f9",
   "metadata": {
    "id": "e95af5f9"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_DataLoader: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
    "                 testing_DataLoader: torch.utils.data.Dataset ,\n",
    "                 epochs: int\n",
    "                 ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.training_DataLoader = training_DataLoader\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.testing_DataLoader = testing_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "\n",
    "    def run_trainer(self):\n",
    "\n",
    "        epoch_train_losses = []\n",
    "        epoch_val_losses = []\n",
    "\n",
    "        times = [0.5, 1, 1.5]\n",
    "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "                 \n",
    "\n",
    "            self.model.train()  # train mode\n",
    "\n",
    "            train_losses=[]\n",
    "            \n",
    "            for x, y in self.training_DataLoader:\n",
    "\n",
    "                x, y = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
    "\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "\n",
    "                out = self.model(x)\n",
    "                #print(f'{y.shape} and {out.shape}')\n",
    "\n",
    "                loss = self.criterion(y, out)\n",
    "                \n",
    "                loss_value = loss.item()\n",
    "                train_losses.append(loss_value)\n",
    "                 \n",
    "                loss.backward()  # one backward pass\n",
    "                self.optimizer.step()  # update the parameters\n",
    "            \n",
    "            epoch_train_losses.append(np.mean(train_losses))\n",
    "            self.model.eval()  # evaluation mode\n",
    "            valid_losses = []  # accumulate the losses here\n",
    "\n",
    "            correct = 0\n",
    "            length = 0\n",
    "            for x,  y in self.validation_DataLoader:\n",
    "\n",
    "                x,y = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    out = self.model(x)\n",
    "                    #print(f'{y.shape} and {out.shape}')\n",
    "                    loss = self.criterion(y, out)\n",
    "                 \n",
    "                    loss_value = loss.item()\n",
    "                    valid_losses.append(loss_value)\n",
    "\n",
    "            epoch_val_losses.append(np.mean(valid_losses))\n",
    "                \n",
    "            # print the results\n",
    "            print(\n",
    "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
    "                end=' '\n",
    "            )\n",
    "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
    "            print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')\n",
    "\n",
    "        return epoch_train_losses, epoch_val_losses\n",
    "        \n",
    "    def evaluate(self):\n",
    "\n",
    "        self.model.eval()\n",
    "        times = [0.5, 1, 1.5]\n",
    "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss = [0,0,0]\n",
    "            length = 0\n",
    "            for x,y in self.testing_DataLoader:\n",
    "\n",
    "                x,y = x.float().to(self.device), y.float().to(self.device)\n",
    "                out = self.model(x)\n",
    "\n",
    "                for i in range(3):\n",
    "                    loss[i] = (out[:,i,:,:] - y[:,i,:,:]).abs().sum(axis = 1).sum(axis = 1).sum()\n",
    "\n",
    "                length+= x.shape[0]*x.shape[2]\n",
    "\n",
    "\n",
    "        print(f'L1 for 0.5 seconds: {loss[0]/length:.4f}; for 1.0 second: {loss[1]/length:.4f}, for 1.5 seconds: {loss[2]/length:.4f}',end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07e03ddf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07e03ddf",
    "outputId": "2f009708-8b08-4480-fe6d-0ee55a6f422d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:02<00:41,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 01/20 LOSS: 2.0467 VAL-LOSS: 1.6151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|████████▎                                                                          | 2/20 [00:04<00:37,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 02/20 LOSS: 1.4105 VAL-LOSS: 1.2167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|████████████▍                                                                      | 3/20 [00:06<00:35,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 03/20 LOSS: 1.0734 VAL-LOSS: 0.9003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|████████████████▌                                                                  | 4/20 [00:08<00:34,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 04/20 LOSS: 0.8283 VAL-LOSS: 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|████████████████████▊                                                              | 5/20 [00:10<00:32,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 05/20 LOSS: 0.6983 VAL-LOSS: 0.6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|████████████████████████▉                                                          | 6/20 [00:12<00:30,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 06/20 LOSS: 0.6137 VAL-LOSS: 0.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 35%|█████████████████████████████                                                      | 7/20 [00:15<00:28,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 07/20 LOSS: 0.5543 VAL-LOSS: 0.5334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [00:17<00:28,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 08/20 LOSS: 0.5088 VAL-LOSS: 0.5010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [00:20<00:25,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 09/20 LOSS: 0.4742 VAL-LOSS: 0.4632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████████████████████████████████████████                                         | 10/20 [00:22<00:23,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10/20 LOSS: 0.4459 VAL-LOSS: 0.4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [00:24<00:21,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11/20 LOSS: 0.4268 VAL-LOSS: 0.4189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [00:27<00:19,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12/20 LOSS: 0.4054 VAL-LOSS: 0.4068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [00:30<00:17,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13/20 LOSS: 0.3916 VAL-LOSS: 0.3908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [00:32<00:14,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14/20 LOSS: 0.3772 VAL-LOSS: 0.3832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [00:34<00:12,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15/20 LOSS: 0.3683 VAL-LOSS: 0.3782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [00:37<00:09,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 16/20 LOSS: 0.3569 VAL-LOSS: 0.3642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [00:39<00:06,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17/20 LOSS: 0.3520 VAL-LOSS: 0.3583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [00:41<00:04,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 18/20 LOSS: 0.3414 VAL-LOSS: 0.3593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [00:43<00:02,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19/20 LOSS: 0.3364 VAL-LOSS: 0.3373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:46<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20/20 LOSS: 0.3269 VAL-LOSS: 0.3404\n",
      "L1 for 0.5 seconds: 0.0034; for 1.0 second: 0.0053, for 1.5 seconds: 0.0078 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "model = ParticleModel(device, set_size = 5, input_size = 5, \n",
    "                 fau1_out = 16, gamma1_out = 32, fau2_out = 32, gamma2_out = 64,\n",
    "                 hidden_dim = 32, output_shape = 2, horizon_length= 3).to(device)\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "TrainingProcedure = Trainer(model, \n",
    "                            device, \n",
    "                            criterion, #torch.nn.BCELoss(),\n",
    "                            optimizer,\n",
    "                            train_dataloader,\n",
    "                            valid_dataloader,\n",
    "                            test_dataloader,\n",
    "                            epochs = 20)\n",
    "\n",
    "\n",
    "\n",
    "train_loss, val_loss = TrainingProcedure.run_trainer()\n",
    "TrainingProcedure.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h4Q2sjnLMF1x",
   "metadata": {
    "id": "h4Q2sjnLMF1x"
   },
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "Qg9_y_vwQWYT",
   "metadata": {
    "id": "Qg9_y_vwQWYT"
   },
   "outputs": [],
   "source": [
    "# (simulation id, parameters (x, y, c, v_x, v_y), particle id)\n",
    "def predict(x, time):\n",
    "    predictions = torch.cat([x[:,0,:]+ time*x[:,-2,:], x[:,1,:] + time*x[:,-1,:]], dim = 1)\n",
    "    return predictions.view((x.shape[0], -1, x.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4h5qIZPJMFW1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4h5qIZPJMFW1",
    "outputId": "1cd458f6-a15f-471a-8abc-81d564aeb619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 for 0.5 seconds: 0.0016; for 1.0 second: 0.0042, for 1.5 seconds: 0.0069 "
     ]
    }
   ],
   "source": [
    "times = [0.5, 1, 1.5]\n",
    "loss = [0,0,0]\n",
    "length = 0\n",
    "for x,y in test_dataloader:    \n",
    "    for i in range(3):\n",
    "        pred = predict(x, times[i])\n",
    "        loss[i] = (pred - y[:,i,:,:]).abs().sum(axis = 1).sum(axis = 1).sum()\n",
    "    length+= x.shape[0]*x.shape[2]\n",
    "\n",
    "print(f'L1 for 0.5 seconds: {loss[0]/length:.4f}; for 1.0 second: {loss[1]/length:.4f}, for 1.5 seconds: {loss[2]/length:.4f}',end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2896299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5625"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0041/0.0016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6fa4a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4285714285714286"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0060/0.0042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1360570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2028985507246377"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 0.0083/0.0069 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1392fb06",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "\n",
    "## Experimantal model №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cdcb8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ParticleModel(torch.nn.Module):\n",
    "    def __init__(self, device, set_size: int = 5, input_size: int = 5, \n",
    "                 fau1_out: int = 32, gamma1_out: int = 32, fau2_out: int = 32, gamma2_out: int = 32,\n",
    "                 hidden_dim: int = 32, output_shape: int = 2, horizon_length: int = 3):\n",
    "        super(ParticleModel, self).__init__()\n",
    "        # first iteration \n",
    "        # layer 1\n",
    "        # input target (x_t, y_t, c_t, v_t) + neighbour (x_n, y_n, c_n, v_n) + edge (distance(t, n)) \n",
    "        # as the result input for first layer is x + x + 1 = 2x + 1 (8 + 1 in our case)\n",
    "        self.fau_iteration1 = nn.Sequential(nn.Linear(input_size*2 + 1, fau1_out),\n",
    "                                            nn.ReLU())\n",
    "        # embeddings are calculated\n",
    "\n",
    "        # layer 2\n",
    "        # input (x_target, y_target, c_target, v_target) + embedding from layer_1\n",
    "        self.gamma_iteration1 = nn.Sequential(nn.Linear(fau1_out+input_size, gamma1_out),\n",
    "                                              nn.ReLU())\n",
    "        self.embedding_size = (set_size, gamma1_out)\n",
    "\n",
    "        # second iteration \n",
    "        # layer 3\n",
    "        # input target (embedding from layer 1) + neigbour (embedding from layer 1) + edge (distance(t, n))\n",
    "        self.fau_iteration2 = nn.Sequential(nn.Linear(gamma1_out*2 + 1, fau2_out),\n",
    "                                            nn.ReLU())\n",
    "        # embeddings are calculated\n",
    "\n",
    "        # layer 4\n",
    "        # input (x_target, y_target, c_target, v_target) + embedding from layer_3\n",
    "        self.gamma_iteration2 = nn.Sequential(nn.Linear(fau2_out + gamma1_out, gamma2_out),\n",
    "                                              nn.ReLU())\n",
    "        self.deepset_output = (set_size, gamma2_out)\n",
    "        \n",
    "\n",
    "        #####\n",
    "        # Recurrent Part\n",
    "        self.rnn = nn.LSTM(gamma2_out*set_size, hidden_dim, num_layers = 3, batch_first = True)\n",
    "\n",
    "        # Fully connected layer after RNN output, to learn more complex relations\n",
    "        self.final = nn.Linear(hidden_dim, output_shape*set_size)\n",
    "\n",
    "        # auxiliary veriable to store the device\n",
    "        self.device = device\n",
    "        self.output_shape = output_shape\n",
    "        self.horizon_length = horizon_length\n",
    "\n",
    "    \n",
    "    def forward_iteration1(self, particle_set, distances):\n",
    "        embedding = torch.zeros((particle_set.shape[0], self.embedding_size[0], self.embedding_size[1])).to(self.device)\n",
    "        \n",
    "        for i in range(particle_set.shape[1]):\n",
    "            # concatenate the neighborhood\n",
    "            x = torch.cat([particle_set[:,i].reshape((particle_set.shape[0], 1, 5)).repeat((1, particle_set.shape[1] - 1, 1)),\n",
    "                           particle_set[:, list(set(range(particle_set.shape[1])).difference({i}))],\n",
    "                           distances[:, i, list(set(range(particle_set.shape[1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
    "                                                                                                   particle_set.shape[1]-1,1))],\n",
    "                          2).to(self.device)\n",
    "\n",
    "\n",
    "            x = self.fau_iteration1(x)\n",
    "\n",
    "            # aggregation function\n",
    "            # mean as a placeholder for now\n",
    "            x = x.max(axis = 1).values.view(x.shape[0], 1, x.shape[2], -1)\n",
    "            # concatenate \n",
    "\n",
    "            x = torch.cat([particle_set[:, i].view(particle_set.shape[0], 1, -1),\n",
    "                           x.view(particle_set.shape[0], 1, -1)],\n",
    "                           dim = 2)\n",
    "            embedding[:,i] = self.gamma_iteration1(x).view(embedding[:,i].shape)\n",
    "        return embedding\n",
    "\n",
    "    def forward_iteration2(self, particle_set, distances):\n",
    "        embedding = torch.zeros((particle_set.shape[0], self.deepset_output[0], self.deepset_output[1])).to(self.device)\n",
    "        for i in range(particle_set.shape[1]):\n",
    "            # concatenate the neighborhood\n",
    "            x = torch.cat([particle_set[:,i].reshape((particle_set.shape[0], 1, particle_set.shape[2])).repeat((1, particle_set.shape[1] - 1, 1)),\n",
    "                           particle_set[:, list(set(range(particle_set.shape[1])).difference({i}))],\n",
    "                           distances[:, i, list(set(range(particle_set.shape[1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
    "                                                                                                   particle_set.shape[1]-1,1))],\n",
    "                          2).to(self.device)\n",
    "\n",
    "            x = self.fau_iteration2(x)\n",
    "\n",
    "            # aggregation function\n",
    "            # mean as a placeholder for now\n",
    "            x = x.max(axis = 1).values.view(x.shape[0], 1, x.shape[2], -1)\n",
    "            \n",
    "            # concatenate \n",
    "            x = torch.cat([particle_set[:, i].view(particle_set.shape[0], 1, -1),\n",
    "                           x.view(particle_set.shape[0], 1, -1)],\n",
    "                           dim = 2)    \n",
    "\n",
    "            embedding[:,i] = self.gamma_iteration2(x).view(embedding[:,i].shape)\n",
    "        return embedding\n",
    "\n",
    "    def forward(self, particle_set):\n",
    "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set[:,:2,:].swapaxes(1,2)], dim=0).to(self.device)\n",
    "        p1 = self.forward_iteration1(particle_set = particle_set, distances = distances)\n",
    "        out = self.forward_iteration2(particle_set=p1, distances=distances).reshape((particle_set.shape[0], 1, -1))\n",
    "        \n",
    "        zeros = torch.zeros((particle_set.shape[0], self.horizon_length, self.deepset_output[0]*self.deepset_output[1])).to(self.device) \n",
    "        #(batch_size, 1, embedding_dim)\n",
    "        rnn_input = torch.cat([out, zeros], dim=1)\n",
    "        \n",
    "        \n",
    "        # Input: (Batch size, L (sequence length), input_shape)\n",
    "        # rnn_output: (Batch size, L (sequence length), output_shape)\n",
    "        rnn_output, rnn_state = self.rnn(rnn_input)\n",
    "\n",
    "        #print(f'{rnn_output[:,1:,:].shape}')\n",
    "        # To further process, put the data through a dense layer\n",
    "        output = self.final(rnn_output[:,1:,:])\n",
    "        \n",
    "        #print(f'{output.shape}')\n",
    "        # (batch_size, horizon_length, output_shape, set_size)\n",
    "        return output.view((output.shape[0], self.horizon_length, self.output_shape, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ad3bd592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:01<00:33,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 01/20 LOSS: 2.1102 VAL-LOSS: 1.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|████████▎                                                                          | 2/20 [00:03<00:31,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 02/20 LOSS: 1.4553 VAL-LOSS: 1.2633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|████████████▍                                                                      | 3/20 [00:05<00:29,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 03/20 LOSS: 1.1409 VAL-LOSS: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|████████████████▌                                                                  | 4/20 [00:06<00:27,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 04/20 LOSS: 0.8860 VAL-LOSS: 0.7871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|████████████████████▊                                                              | 5/20 [00:08<00:25,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 05/20 LOSS: 0.7373 VAL-LOSS: 0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|████████████████████████▉                                                          | 6/20 [00:10<00:24,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 06/20 LOSS: 0.6436 VAL-LOSS: 0.6083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 35%|█████████████████████████████                                                      | 7/20 [00:12<00:22,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 07/20 LOSS: 0.5815 VAL-LOSS: 0.5513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [00:13<00:20,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 08/20 LOSS: 0.5322 VAL-LOSS: 0.5146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [00:15<00:19,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 09/20 LOSS: 0.4967 VAL-LOSS: 0.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████████████████████████████████████████                                         | 10/20 [00:17<00:17,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10/20 LOSS: 0.4689 VAL-LOSS: 0.4538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [00:19<00:15,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11/20 LOSS: 0.4434 VAL-LOSS: 0.4352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [00:20<00:14,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12/20 LOSS: 0.4244 VAL-LOSS: 0.4187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [00:22<00:12,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13/20 LOSS: 0.4104 VAL-LOSS: 0.4137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [00:24<00:10,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14/20 LOSS: 0.3969 VAL-LOSS: 0.4046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [00:26<00:08,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15/20 LOSS: 0.3828 VAL-LOSS: 0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [00:28<00:07,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 16/20 LOSS: 0.3752 VAL-LOSS: 0.3749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [00:30<00:05,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17/20 LOSS: 0.3633 VAL-LOSS: 0.3660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [00:32<00:03,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 18/20 LOSS: 0.3562 VAL-LOSS: 0.3639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [00:34<00:01,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19/20 LOSS: 0.3480 VAL-LOSS: 0.3596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20/20 LOSS: 0.3431 VAL-LOSS: 0.3473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "model = ParticleModel(device, set_size = 5, input_size = 5, \n",
    "                 fau1_out = 8, gamma1_out = 16, fau2_out = 16, gamma2_out = 32,\n",
    "                 hidden_dim = 32, output_shape = 2, horizon_length= 3).to(device)\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "TrainingProcedure = Trainer(model, \n",
    "                            device, \n",
    "                            criterion, #torch.nn.BCELoss(),\n",
    "                            optimizer,\n",
    "                            train_dataloader,\n",
    "                            valid_dataloader,\n",
    "                            test_dataloader,\n",
    "                            epochs = 20)\n",
    "\n",
    "\n",
    "\n",
    "train_loss, val_loss = TrainingProcedure.run_trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7aecf5",
   "metadata": {},
   "source": [
    "avg pooling: L1 for 0.5 seconds: 0.0041; for 1.0 second: 0.0060, for 1.5 seconds: 0.0083 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30747903",
   "metadata": {},
   "source": [
    "max pooling: L1 for 0.5 seconds: 0.0038; for 1.0 second: 0.0055, for 1.5 seconds: 0.0078 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfe517",
   "metadata": {},
   "source": [
    "min pooling: L1 for 0.5 seconds: 0.0037; for 1.0 second: 0.0057, for 1.5 seconds: 0.0083 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fd2ac7",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c664073",
   "metadata": {},
   "source": [
    "## Experimental model (ParticleGNN)\n",
    "\n",
    "https://arxiv.org/pdf/2102.09844.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "350155fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5, 5])\n",
      "torch.Size([64, 3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# x_train shape: (simulation id, parameters (x, y, c, v_x, v_y), particle id)\n",
    "# y_train shape: (simulation id, time (0.5, 1, 1.5), (x, y), particle id)\n",
    "\n",
    "tf, tl = next(iter(train_dataloader))\n",
    "\n",
    "print(tf.shape)\n",
    "print(tl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77c1ce8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 5])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf[:,-2:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "dca34a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleGNN(torch.nn.Module):\n",
    "    def __init__(self, device, set_size: int = 5, \n",
    "                 input_size: int = 1, n_emb: int = 8, coord_size: int = 2, c_emb: int = 8,\n",
    "                 fau1_embedding: int = 8, gamma1_embedding: int = 8, output_size: int = 2):\n",
    "        super(ParticleGNN, self).__init__()\n",
    "        # node embedding (charge to embedding)\n",
    "        self.node_embedding = nn.Sequential(nn.Linear(input_size*set_size, n_emb*set_size),\n",
    "                                            nn.ReLU())\n",
    "        # coordinates embedding (coordinates to embedding)\n",
    "        self.coord_embedding = nn.Sequential(nn.Linear(coord_size*set_size, c_emb*set_size),\n",
    "                                             nn.ReLU())\n",
    "            \n",
    "        self.velocity_embedding = nn.Sequential(nn.Linear(coord_size*set_size, c_emb*set_size),\n",
    "                                                nn.ReLU())\n",
    "        # fau function to get the information about the neighborhood\n",
    "        # input (target node emb + neighbour node emb + distance (based on coord emb))\n",
    "        # output fau1_embedding\n",
    "        self.fau_iteration1 = nn.Sequential(nn.Linear(n_emb*2 + 1, fau1_embedding),\n",
    "                                            nn.ReLU())\n",
    "        \n",
    "        # node embedding to the velocity parameter function \n",
    "        self.fau_velocity = nn.Sequential(nn.Linear(n_emb, c_emb),\n",
    "                                            nn.ReLU())\n",
    "        \n",
    "        #gamma function to update the state of the target node\n",
    "        self.gamma_iteration1 = nn.Sequential(nn.Linear(n_emb + fau1_embedding, n_emb),\n",
    "                                              nn.ReLU())\n",
    "            \n",
    "        self.final_linear = nn.Sequential(nn.Linear(n_emb, output_size))\n",
    "        self.coord_size = coord_size\n",
    "        self.constant = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "        \n",
    "        self.device = device\n",
    "            \n",
    "    def forward_iteration(self, node_emb, coord_emb, velocity_emb):\n",
    "        # all have shape (batch size, embedding size, set size)\n",
    "        distances = torch.stack([torch.cdist(x_i,x_i) for x_i in coord_emb.swapaxes(1,2)], dim=0).to(self.device)\n",
    "        new_node_emb = torch.zeros(node_emb.shape).to(self.device)\n",
    "        new_coord_emb = torch.zeros(coord_emb.shape).to(self.device)\n",
    "        new_velocity_emb = torch.zeros(velocity_emb.shape).to(self.device)\n",
    "        \n",
    "        for i in range(node_emb.shape[-1]):\n",
    "            # get representation of the neighborhood\n",
    "            # concatenate\n",
    "            x = torch.cat([node_emb[:,:,i].view((node_emb.shape[0], node_emb.shape[1], -1))\\\n",
    "                                          .repeat((1,1,node_emb.shape[-1] - 1)).to(self.device),\n",
    "                           node_emb[:,:,list(set(range(node_emb.shape[-1])).difference({i}))].to(self.device),\n",
    "                           distances[:, i, list(set(range(node_emb.shape[-1])).difference({i}))]\\\n",
    "                                          .view(node_emb.shape[0], 1, -1).to(self.device)],\n",
    "                         dim = 1)\n",
    "\n",
    "            x = self.fau_iteration1(x.swapaxes(1,2)).to(self.device)\n",
    "            coord_diff = node_emb[:,:,i].view((node_emb.shape[0], node_emb.shape[1], 1)).repeat((1,1,node_emb.shape[-1] - 1)) -\\\n",
    "                  node_emb[:,:,list(set(range(node_emb.shape[-1])).difference({i}))].to(self.device)\n",
    "\n",
    "            # update velocity\n",
    "            new_velocity_emb[:,:,i] = velocity_emb[:,:,i]*self.fau_velocity(node_emb[:,:,i])+self.constant*(x*coord_diff.swapaxes(1,2)).sum(axis=1)\n",
    "\n",
    "            # update coordinates\n",
    "            new_coord_emb[:,:,i] = coord_emb[:,:,i]+new_velocity_emb[:,:,i]\n",
    "\n",
    "            # update the embedding\n",
    "            # can replace with another aggregation function\n",
    "            new_node_emb[:,:,i] = self.gamma_iteration1(torch.cat([x.sum(axis = 1).view((x.shape[0], -1)),\n",
    "                                              node_emb[:,:,i]], axis = 1)).to(self.device)\n",
    "        \n",
    "        return new_node_emb, new_coord_emb, new_velocity_emb\n",
    "    \n",
    "    def get_embeddings(self, particle_set):        \n",
    "        node_emb = self.node_embedding(particle_set[:,2,:].view(particle_set.shape[0], -1))\\\n",
    "                       .view((particle_set.shape[0], -1, particle_set.shape[-1])).to(self.device)\n",
    "        \n",
    "        coord_emb = self.coord_embedding(particle_set[:,:2,:].view(particle_set.shape[0], -1))\\\n",
    "                        .view((particle_set.shape[0], -1, particle_set.shape[-1])).to(self.device)\n",
    "        \n",
    "        velocity_emb = self.velocity_embedding(particle_set[:,-2:,:].view(particle_set.shape[0], -1))\\\n",
    "                           .view((particle_set.shape[0], -1, particle_set.shape[-1])).to(self.device)\n",
    "        \n",
    "        return node_emb, coord_emb, velocity_emb\n",
    "    \n",
    "    def get_coordinates(self, node_emb):\n",
    "        coordinates = self.final_linear(node_emb.swapaxes(1,2))\n",
    "        return coordinates.view((node_emb.shape[0], coordinates.shape[-1], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e862ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class RecurrentTrainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_DataLoader: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
    "                 testing_DataLoader: torch.utils.data.Dataset ,\n",
    "                 epochs: int\n",
    "                 ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.training_DataLoader = training_DataLoader\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.testing_DataLoader = testing_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "\n",
    "    def run_trainer(self, time_horizon: int = 3):\n",
    "\n",
    "        epoch_train_losses = []\n",
    "        epoch_val_losses = []\n",
    "\n",
    "        times = [0.5, 1, 1.5]\n",
    "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "                 \n",
    "\n",
    "            self.model.train()  # train mode\n",
    "\n",
    "            train_losses=[]\n",
    "            \n",
    "            for x, y in self.training_DataLoader:\n",
    "\n",
    "                x, y = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
    "                predictions = torch.zeros(y.shape)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                \n",
    "                embed = []\n",
    "                embed.append(model.get_embeddings(x))\n",
    "                \n",
    "                for t in range(time_horizon):\n",
    "                    tne, tce, tve = model.forward_iteration(embed[t][0],embed[t][1],embed[t][2])\n",
    "                    predictions[:,t,:,:] = model.get_coordinates(tne)\n",
    "                    \n",
    "                    embed.append((tne, tce, tve))\n",
    "                    \n",
    "                #print(f'{y.shape} and {out.shape}')\n",
    "\n",
    "                loss = self.criterion(y, predictions)\n",
    "                \n",
    "                loss_value = loss.item()\n",
    "                train_losses.append(loss_value)\n",
    "                 \n",
    "                loss.backward()  # one backward pass\n",
    "                self.optimizer.step()  # update the parameters\n",
    "            \n",
    "            epoch_train_losses.append(np.mean(train_losses))\n",
    "            self.model.eval()  # evaluation mode\n",
    "            valid_losses = []  # accumulate the losses here\n",
    "\n",
    "            correct = 0\n",
    "            length = 0\n",
    "            for x,  y in self.validation_DataLoader:\n",
    "\n",
    "                x,y = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
    "                \n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    predictions = torch.zeros(y.shape)\n",
    "                    self.optimizer.zero_grad()  # zerograd the parameters\n",
    "\n",
    "                    embed = []\n",
    "                    embed.append(model.get_embeddings(x))\n",
    "                    \n",
    "                    for t in range(time_horizon):\n",
    "                        tne, tce, tve = model.forward_iteration(embed[t][0],embed[t][1],embed[t][2])\n",
    "                        predictions[:,t,:,:] = model.get_coordinates(tne)\n",
    "                        embed.append((tne, tce, tve))\n",
    "                    #print(f'{y.shape} and {out.shape}')\n",
    "                    loss = self.criterion(y, predictions)\n",
    "                 \n",
    "                    loss_value = loss.item()\n",
    "                    valid_losses.append(loss_value)\n",
    "\n",
    "            epoch_val_losses.append(np.mean(valid_losses))\n",
    "                \n",
    "            # print the results\n",
    "            print(\n",
    "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
    "                end=' '\n",
    "            )\n",
    "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
    "            print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')\n",
    "\n",
    "        return epoch_train_losses, epoch_val_losses\n",
    "        \n",
    "    def evaluate(self, time_horizon):\n",
    "\n",
    "        self.model.eval()\n",
    "        times = [0.5, 1, 1.5]\n",
    "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss = [0,0,0]\n",
    "            length = 0\n",
    "            for x,y in self.testing_DataLoader:\n",
    "\n",
    "                x,y = x.float().to(self.device), y.float().to(self.device)\n",
    "                predictions = torch.zeros(y.shape)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                \n",
    "                embed = []\n",
    "                embed.append(model.get_embeddings(x))\n",
    "                \n",
    "                for t in range(time_horizon):\n",
    "                    tne, tce, tve = model.forward_iteration(embed[t][0],embed[t][1],embed[t][2])\n",
    "                    predictions[:,t,:,:] = model.get_coordinates(tne)\n",
    "                    embed.append((tne, tce, tve))\n",
    "\n",
    "                for i in range(3):\n",
    "                    loss[i] = (predictions[:,i,:,:] - y[:,i,:,:]).abs().sum(axis = 1).sum(axis = 1).sum()\n",
    "\n",
    "                length+= x.shape[0]*x.shape[2]\n",
    "\n",
    "\n",
    "        print(f'L1 for 0.5 seconds: {loss[0]/length:.4f}; for 1.0 second: {loss[1]/length:.4f}, for 1.5 seconds: {loss[2]/length:.4f}',end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "9fc7d26a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:04<01:27,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 01/20 LOSS: 2.4012 VAL-LOSS: 2.3391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|████████▎                                                                          | 2/20 [00:09<01:22,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 02/20 LOSS: 2.2064 VAL-LOSS: 1.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|████████████▍                                                                      | 3/20 [00:13<01:17,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 03/20 LOSS: 1.8725 VAL-LOSS: 1.7725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|████████████████▌                                                                  | 4/20 [00:18<01:13,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 04/20 LOSS: 1.7483 VAL-LOSS: 1.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|████████████████████▊                                                              | 5/20 [00:22<01:08,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 05/20 LOSS: 1.6831 VAL-LOSS: 1.6408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|████████████████████████▉                                                          | 6/20 [00:27<01:03,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 06/20 LOSS: 1.6366 VAL-LOSS: 1.6010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 35%|█████████████████████████████                                                      | 7/20 [00:32<00:59,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 07/20 LOSS: 1.5973 VAL-LOSS: 1.5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [00:36<00:55,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 08/20 LOSS: 1.5601 VAL-LOSS: 1.5242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [00:41<00:50,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 09/20 LOSS: 1.5276 VAL-LOSS: 1.4936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████████████████████████████████████████                                         | 10/20 [00:46<00:46,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10/20 LOSS: 1.4956 VAL-LOSS: 1.4711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [00:50<00:41,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11/20 LOSS: 1.4720 VAL-LOSS: 1.4424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [00:55<00:36,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12/20 LOSS: 1.4491 VAL-LOSS: 1.4222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [00:59<00:32,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13/20 LOSS: 1.4305 VAL-LOSS: 1.4089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [01:04<00:27,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14/20 LOSS: 1.4169 VAL-LOSS: 1.3974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [01:09<00:23,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15/20 LOSS: 1.4030 VAL-LOSS: 1.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [01:13<00:18,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 16/20 LOSS: 1.3908 VAL-LOSS: 1.3671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [01:18<00:13,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17/20 LOSS: 1.3811 VAL-LOSS: 1.3637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [01:23<00:09,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 18/20 LOSS: 1.3736 VAL-LOSS: 1.3561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [01:27<00:04,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19/20 LOSS: 1.3641 VAL-LOSS: 1.3410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:32<00:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20/20 LOSS: 1.3592 VAL-LOSS: 1.3387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "model = ParticleGNN(device).to(device)\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "TrainingProcedure = RecurrentTrainer(model, \n",
    "                            device, \n",
    "                            criterion, #torch.nn.BCELoss(),\n",
    "                            optimizer,\n",
    "                            train_dataloader,\n",
    "                            valid_dataloader,\n",
    "                            test_dataloader,\n",
    "                            epochs = 20)\n",
    "\n",
    "\n",
    "\n",
    "train_loss, val_loss = TrainingProcedure.run_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "77d62800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 for 0.5 seconds: 0.0208; for 1.0 second: 0.0221, for 1.5 seconds: 0.0250 "
     ]
    }
   ],
   "source": [
    "TrainingProcedure.evaluate(time_horizon = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc83248",
   "metadata": {},
   "source": [
    "----\n",
    "### Stupid LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3f8df995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self, device, set_size: int = 5, input_size: int = 5, \n",
    "                 emb1: int = 16, emb2: int = 32, emb3: int = 64,\n",
    "                 hidden_dim: int = 64, output_shape: int = 2, horizon_length: int = 3):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(nn.Linear(set_size*input_size, set_size*emb1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm1d(set_size*emb1),\n",
    "                                    nn.Linear(set_size*emb1, set_size*emb2),\n",
    "                                    nn.ReLU())\n",
    "        \n",
    "        self.layer2 = nn.Sequential(nn.Linear(emb2*2*set_size, emb3*set_size), nn.ReLU())\n",
    "        \n",
    "        \n",
    "        #####\n",
    "        # Recurrent Part\n",
    "        self.rnn = nn.LSTM(emb3*set_size, hidden_dim, num_layers = 1, batch_first = True)\n",
    "        \n",
    "        # Fully connected layer after RNN output, to learn more complex relations\n",
    "        self.final = nn.Linear(hidden_dim, output_shape*set_size)\n",
    "\n",
    "        # auxiliary veriable to store the device\n",
    "        self.device = device\n",
    "        self.output_shape = output_shape\n",
    "        self.horizon_length = horizon_length\n",
    "\n",
    "    \n",
    "    def forward(self, particle_set):\n",
    "                                    \n",
    "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set[:,:2,:].swapaxes(1,2)], dim=0).to(self.device)\n",
    "\n",
    "        embeddings = self.layer1(particle_set.view(particle_set.shape[0], -1)).view(particle_set.shape[0],-1,particle_set.shape[-1])\n",
    "        embeddings2 = torch.zeros((embeddings.shape[0], embeddings.shape[1]*2, embeddings.shape[-1]))              \n",
    "        for i in range(embeddings.shape[-1]):\n",
    "            embeddings2[:,:,i] = torch.concat([embeddings[:,:,i].view(embeddings.shape[0], embeddings.shape[1]),\n",
    "                                               embeddings[:,:,list(set(range(embeddings.shape[-1])).difference({i}))]\\\n",
    "                                                  .view(embeddings.shape[0], -1, particle_set.shape[-1] - 1)\\\n",
    "                                                  .max(dim=2).values], dim = 1)\n",
    "            \n",
    "        embeddings2 = self.layer2(embeddings2.view(particle_set.shape[0], 1, -1))\n",
    "                                    \n",
    "        zeros = torch.zeros((particle_set.shape[0], self.horizon_length, embeddings2.shape[-1])).to(self.device) \n",
    "        #(batch_size, 1, embedding_dim)\n",
    "        rnn_input = torch.cat([embeddings2, zeros], dim=1)\n",
    "        \n",
    "        \n",
    "        # Input: (Batch size, L (sequence length), input_shape)\n",
    "        # rnn_output: (Batch size, L (sequence length), output_shape)\n",
    "        rnn_output, rnn_state = self.rnn(rnn_input)\n",
    "\n",
    "        #print(f'{rnn_output[:,1:,:].shape}')\n",
    "        # To further process, put the data through a dense layer\n",
    "        output = self.final(rnn_output[:,1:,:])\n",
    "        \n",
    "        #print(f'{output.shape}')\n",
    "        # (batch_size, horizon_length, output_shape, set_size)\n",
    "        return output.view((output.shape[0], self.horizon_length, self.output_shape, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b244d013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:01<00:30,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 01/20 LOSS: 1.7340 VAL-LOSS: 1.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|████████▎                                                                          | 2/20 [00:03<00:30,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 02/20 LOSS: 1.1325 VAL-LOSS: 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|████████████▍                                                                      | 3/20 [00:04<00:27,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 03/20 LOSS: 0.9011 VAL-LOSS: 0.7319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|████████████████▌                                                                  | 4/20 [00:06<00:26,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 04/20 LOSS: 0.7966 VAL-LOSS: 0.6605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|████████████████████▊                                                              | 5/20 [00:08<00:24,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 05/20 LOSS: 0.7369 VAL-LOSS: 0.6871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|████████████████████████▉                                                          | 6/20 [00:09<00:23,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 06/20 LOSS: 0.6911 VAL-LOSS: 0.6221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 35%|█████████████████████████████                                                      | 7/20 [00:11<00:22,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 07/20 LOSS: 0.6553 VAL-LOSS: 0.5888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [00:13<00:20,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 08/20 LOSS: 0.6372 VAL-LOSS: 0.5424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [00:15<00:18,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 09/20 LOSS: 0.6218 VAL-LOSS: 0.5353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████████████████████████████████████████                                         | 10/20 [00:16<00:17,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10/20 LOSS: 0.6144 VAL-LOSS: 0.5151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [00:18<00:15,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11/20 LOSS: 0.6018 VAL-LOSS: 0.5177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [00:20<00:14,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12/20 LOSS: 0.5957 VAL-LOSS: 0.4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [00:22<00:12,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13/20 LOSS: 0.5718 VAL-LOSS: 0.5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [00:24<00:10,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14/20 LOSS: 0.5811 VAL-LOSS: 0.4677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [00:25<00:08,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15/20 LOSS: 0.5644 VAL-LOSS: 0.4847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [00:27<00:07,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 16/20 LOSS: 0.5634 VAL-LOSS: 0.4975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [00:29<00:05,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17/20 LOSS: 0.5648 VAL-LOSS: 0.4613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [00:31<00:03,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 18/20 LOSS: 0.5541 VAL-LOSS: 0.4781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [00:33<00:01,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19/20 LOSS: 0.5561 VAL-LOSS: 0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20/20 LOSS: 0.5453 VAL-LOSS: 0.4639\n",
      "L1 for 0.5 seconds: 0.0058; for 1.0 second: 0.0075, for 1.5 seconds: 0.0099 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "model =  SimpleModel(device).to(device)\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "TrainingProcedure = Trainer(model, \n",
    "                            device, \n",
    "                            criterion, #torch.nn.BCELoss(),\n",
    "                            optimizer,\n",
    "                            train_dataloader,\n",
    "                            valid_dataloader,\n",
    "                            test_dataloader,\n",
    "                            epochs = 20)\n",
    "\n",
    "\n",
    "\n",
    "train_loss, val_loss = TrainingProcedure.run_trainer()\n",
    "TrainingProcedure.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f28168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {
    "id": "d5fb3b29"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed539a8",
   "metadata": {
    "id": "5ed539a8"
   },
   "source": [
    "### Some ideas on the experimental part:\n",
    "\n",
    "* Try various aggregation functions: Mean, Pooling (Max and Min)\n",
    "* Compare different target time as an input\n",
    "* Check different losses\n",
    "* Regularization to the embeddings (linear layers) (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fa1b4",
   "metadata": {
    "id": "bf5fa1b4"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280031f",
   "metadata": {
    "id": "2280031f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786abddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "a2_RNN.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "b001d610a241339cc3b7988a7f6c804c70cb4dbbf032519cbfea0d67797e8b2b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
