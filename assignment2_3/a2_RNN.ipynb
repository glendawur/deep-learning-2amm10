{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {
    "id": "d32f8d18"
   },
   "source": [
    "# Group Number:\n",
    "\n",
    "# Student 1: Ryan Meghoe\n",
    "\n",
    "# Student 2: Nikita Jain\n",
    "\n",
    "# Student 3: Andrei Rykov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {
    "id": "faec2056"
   },
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {
    "id": "7d0580a5"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc346bc",
   "metadata": {
    "id": "8fc346bc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0756591",
   "metadata": {
    "id": "b0756591"
   },
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_array(zipfile, fn):\n",
    "    return np.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb77a4be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb77a4be",
    "outputId": "e5562ffc-e8b8-43de-cd53-a1d1b8ad2da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the training data:\n",
      "\n",
      "positions: (10000, 4, 2, 5)\n",
      "velocities: (10000, 1, 2, 5)\n",
      "charges: (10000, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell loads the training, validation or test data as numpy arrays,\n",
    "with the positions, initial velocities and charge data of the particles.\n",
    "\n",
    "The position arrays are shaped as\n",
    "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
    "\n",
    "The initial velocity arrays are shaped as\n",
    "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
    "\n",
    "The charge arrays are shaped as [simulation id, particle id, 1]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
    "\n",
    "features = ['positions', 'velocities', 'charges']\n",
    "    \n",
    "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
    "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
    "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
    "\n",
    "print('Shapes of the training data:\\n')\n",
    "print(f'positions: {positions_train.shape}')\n",
    "print(f'velocities: {velocities_train.shape}')\n",
    "print(f'charges: {charges_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3ea4cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c3ea4cb",
    "outputId": "fe3f76c1-7e8c-481d-c310-610e1c438cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of retrieving data from the arrays:\n",
      "\n",
      "\n",
      "In simulation 42 of the training set, particle 3 with charge -1.0 had coordinates [ 2.05159559 -1.46130851].\n",
      "The initial velocity of this particle was [ 0.28402364 -0.24784824].\n"
     ]
    }
   ],
   "source": [
    "print('An example of retrieving data from the arrays:\\n\\n')\n",
    "\n",
    "sim_idx = 42\n",
    "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
    "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
    "particle_idx = 3  # corresponds to particle with index 3\n",
    "\n",
    "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
    "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
    "c = charges_train[sim_idx, particle_idx, 0] \n",
    "\n",
    "print(\n",
    "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a3438a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10a3438a",
    "outputId": "01d1f87c-6d4f-4c06-f2a2-b7cf5c3caf56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "10000 train, 2000 validation, 2000 test simulations\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9106543",
   "metadata": {
    "id": "f9106543"
   },
   "outputs": [],
   "source": [
    "def plot_example(pos, vel):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(pos.shape[-1]):\n",
    "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
    "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
    "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.plot([], [], 'd', color='black', label='initial position')\n",
    "    plt.plot([], [], 'x', color='black', label='final position')\n",
    "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28681a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "d28681a6",
    "outputId": "afd726bd-9de5-4118-eb22-02689717a04f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = np.random.randint(0, 10000)\n",
    "plot_example(positions_train[random_idx], velocities_train[random_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {
    "id": "059b633c"
   },
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ecb529",
   "metadata": {
    "id": "e6ecb529"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train = torch.cat((torch.tensor(positions_train[:,0,:,:]), torch.tensor(charges_train).squeeze(-1).unsqueeze(1)), dim=1)\n",
    "X_train = torch.cat((X_train, torch.tensor(velocities_train).squeeze(1)), dim=1) # shape: (simulation id, parameters (x, y, c, v_x, v_y), particle id)\n",
    "y_train = torch.tensor(positions_train[:,1:,:,:]) # shape: (simulation id, time (0.5, 1, 1.5), (x, y), particle id)\n",
    "\n",
    "X_valid = torch.cat((torch.tensor(positions_valid[:,0,:,:]), torch.tensor(charges_valid).squeeze(-1).unsqueeze(1)), dim=1)\n",
    "X_valid = torch.cat((X_valid, torch.tensor(velocities_valid).squeeze(1)), dim=1)\n",
    "y_valid = torch.tensor(positions_valid[:,1:,:,:])\n",
    "\n",
    "X_test = torch.cat((torch.tensor(positions_test[:,0,:,:]), torch.tensor(charges_test).squeeze(-1).unsqueeze(1)), dim=1)\n",
    "X_test = torch.cat((X_test, torch.tensor(velocities_test).squeeze(1)), dim=1)\n",
    "y_test = torch.tensor(positions_test[:,1:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8633eb8",
   "metadata": {
    "id": "f8633eb8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a99a32b",
   "metadata": {
    "id": "0a99a32b"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {
    "id": "18b2874d"
   },
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66774050",
   "metadata": {
    "id": "66774050"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ParticleModel(torch.nn.Module):\n",
    "    def __init__(self, device, set_size: int = 5, input_size: int = 5, \n",
    "                 fau1_out: int = 32, gamma1_out: int = 32, fau2_out: int = 32, gamma2_out: int = 32,\n",
    "                 hidden_dim: int = 32, output_shape: int = 2, horizon_length: int = 3):\n",
    "        super(ParticleModel, self).__init__()\n",
    "        # first iteration \n",
    "        # layer 1\n",
    "        # input target (x_t, y_t, c_t, v_t) + neighbour (x_n, y_n, c_n, v_n) + edge (distance(t, n)) \n",
    "        # as the result input for first layer is x + x + 1 = 2x + 1 (8 + 1 in our case)\n",
    "        self.fau_iteration1 = nn.Sequential(nn.Linear(input_size*2 + 1, fau1_out),\n",
    "                                            nn.ReLU())\n",
    "        # embeddings are calculated\n",
    "\n",
    "        # layer 2\n",
    "        # input (x_target, y_target, c_target, v_target) + embedding from layer_1\n",
    "        self.gamma_iteration1 = nn.Sequential(nn.Linear(fau1_out+input_size, gamma1_out),\n",
    "                                              nn.ReLU())\n",
    "        self.embedding_size = (set_size, gamma1_out)\n",
    "\n",
    "        # second iteration \n",
    "        # layer 3\n",
    "        # input target (embedding from layer 1) + neigbour (embedding from layer 1) + edge (distance(t, n))\n",
    "        self.fau_iteration2 = nn.Sequential(nn.Linear(gamma1_out*2 + 1, fau2_out),\n",
    "                                            nn.ReLU())\n",
    "        # embeddings are calculated\n",
    "\n",
    "        # layer 4\n",
    "        # input (x_target, y_target, c_target, v_target) + embedding from layer_3\n",
    "        self.gamma_iteration2 = nn.Sequential(nn.Linear(fau2_out + gamma1_out, gamma2_out),\n",
    "                                              nn.ReLU())\n",
    "        self.deepset_output = (set_size, gamma2_out)\n",
    "        \n",
    "\n",
    "        #####\n",
    "        # Recurrent Part\n",
    "        self.rnn = nn.LSTM(gamma2_out*set_size, hidden_dim, num_layers = 1, batch_first = True)\n",
    "\n",
    "        # Fully connected layer after RNN output, to learn more complex relations\n",
    "        self.final = nn.Linear(hidden_dim, output_shape*set_size)\n",
    "\n",
    "        # auxiliary veriable to store the device\n",
    "        self.device = device\n",
    "        self.output_shape = output_shape\n",
    "        self.horizon_length = horizon_length\n",
    "\n",
    "    \n",
    "    def forward_iteration1(self, particle_set, distances):\n",
    "        embedding = torch.zeros((particle_set.shape[0], self.embedding_size[0], self.embedding_size[1])).to(self.device)\n",
    "        \n",
    "        for i in range(particle_set.shape[1]):\n",
    "            # concatenate the neighborhood\n",
    "            x = torch.cat([particle_set[:,i].reshape((particle_set.shape[0], 1, 5)).repeat((1, particle_set.shape[1] - 1, 1)),\n",
    "                           particle_set[:, list(set(range(particle_set.shape[1])).difference({i}))],\n",
    "                           distances[:, i, list(set(range(particle_set.shape[1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
    "                                                                                                   particle_set.shape[1]-1,1))],\n",
    "                          2).to(self.device)\n",
    "\n",
    "\n",
    "            x = self.fau_iteration1(x)\n",
    "\n",
    "            # aggregation function\n",
    "            # mean as a placeholder for now\n",
    "            x = x.mean(axis = 1)\n",
    "            # concatenate \n",
    "            x = torch.cat([particle_set[:, i].view(particle_set.shape[0], 1, -1),\n",
    "                           x.view(particle_set.shape[0], 1, -1)],\n",
    "                           dim = 2)\n",
    "            embedding[:,i] = self.gamma_iteration1(x).view(embedding[:,i].shape)\n",
    "        return embedding\n",
    "\n",
    "    def forward_iteration2(self, particle_set, distances):\n",
    "        embedding = torch.zeros((particle_set.shape[0], self.deepset_output[0], self.deepset_output[1])).to(self.device)\n",
    "        for i in range(particle_set.shape[1]):\n",
    "            # concatenate the neighborhood\n",
    "            x = torch.cat([particle_set[:,i].reshape((particle_set.shape[0], 1, particle_set.shape[2])).repeat((1, particle_set.shape[1] - 1, 1)),\n",
    "                           particle_set[:, list(set(range(particle_set.shape[1])).difference({i}))],\n",
    "                           distances[:, i, list(set(range(particle_set.shape[1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
    "                                                                                                   particle_set.shape[1]-1,1))],\n",
    "                          2).to(self.device)\n",
    "\n",
    "            x = self.fau_iteration2(x)\n",
    "\n",
    "            # aggregation function\n",
    "            # mean as a placeholder for now\n",
    "            x = x.mean(axis = 1)\n",
    "\n",
    "            \n",
    "            # concatenate \n",
    "            x = torch.cat([particle_set[:, i].view(particle_set.shape[0], 1, -1),\n",
    "                           x.view(particle_set.shape[0], 1, -1)],\n",
    "                           dim = 2)    \n",
    "\n",
    "            embedding[:,i] = self.gamma_iteration2(x).view(embedding[:,i].shape)\n",
    "        return embedding\n",
    "\n",
    "    def forward(self, particle_set):\n",
    "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set], dim=0).to(self.device)\n",
    "        p1 = self.forward_iteration1(particle_set = particle_set, distances = distances)\n",
    "        out = self.forward_iteration2(particle_set=p1, distances=distances).reshape((particle_set.shape[0], 1, -1))\n",
    "        \n",
    "        zeros = torch.zeros((particle_set.shape[0], self.horizon_length, self.deepset_output[0]*self.deepset_output[1])).to(self.device) \n",
    "        #(batch_size, 1, embedding_dim)\n",
    "        rnn_input = torch.cat([out, zeros], dim=1)\n",
    "        \n",
    "        \n",
    "        # Input: (Batch size, L (sequence length), input_shape)\n",
    "        # rnn_output: (Batch size, L (sequence length), output_shape)\n",
    "        rnn_output, rnn_state = self.rnn(rnn_input)\n",
    "\n",
    "        #print(f'{rnn_output[:,1:,:].shape}')\n",
    "        # To further process, put the data through a dense layer\n",
    "        output = self.final(rnn_output[:,1:,:])\n",
    "        \n",
    "        #print(f'{output.shape}')\n",
    "        # (batch_size, horizon_length, output_shape, set_size)\n",
    "        return output.view((output.shape[0], self.horizon_length, self.output_shape, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982e20f4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc148649",
   "metadata": {},
   "source": [
    "Model check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56996c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "model = ParticleModel(device, set_size = 5, input_size = 5, \n",
    "                 fau1_out = 8, gamma1_out = 16, fau2_out = 16, gamma2_out = 32,\n",
    "                 hidden_dim = 32, output_shape = 2, horizon_length= 3).to(device)\n",
    "\n",
    "tf, tl = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f381298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32])\n",
      "torch.Size([64, 3, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 2, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.float().to(device)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {
    "id": "dea70d73"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e95af5f9",
   "metadata": {
    "id": "e95af5f9"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_DataLoader: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
    "                 testing_DataLoader: torch.utils.data.Dataset ,\n",
    "                 epochs: int\n",
    "                 ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.training_DataLoader = training_DataLoader\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.testing_DataLoader = testing_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "\n",
    "    def run_trainer(self):\n",
    "\n",
    "        epoch_train_losses = []\n",
    "        epoch_val_losses = []\n",
    "\n",
    "        times = [0.5, 1, 1.5]\n",
    "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "                 \n",
    "\n",
    "            self.model.train()  # train mode\n",
    "\n",
    "            train_losses=[]\n",
    "            \n",
    "            for x, y in self.training_DataLoader:\n",
    "\n",
    "                x, y = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
    "\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "\n",
    "                out = self.model(x)\n",
    "                #print(f'{y.shape} and {out.shape}')\n",
    "\n",
    "                loss = self.criterion(y, out)\n",
    "                \n",
    "                loss_value = loss.item()\n",
    "                train_losses.append(loss_value)\n",
    "                 \n",
    "                loss.backward()  # one backward pass\n",
    "                self.optimizer.step()  # update the parameters\n",
    "            \n",
    "            epoch_train_losses.append(np.mean(train_losses))\n",
    "            self.model.eval()  # evaluation mode\n",
    "            valid_losses = []  # accumulate the losses here\n",
    "\n",
    "            correct = 0\n",
    "            length = 0\n",
    "            for x,  y in self.validation_DataLoader:\n",
    "\n",
    "                x,y = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    out = self.model(x)\n",
    "                    #print(f'{y.shape} and {out.shape}')\n",
    "                    loss = self.criterion(y, out)\n",
    "                 \n",
    "                    loss_value = loss.item()\n",
    "                    valid_losses.append(loss_value)\n",
    "\n",
    "            epoch_val_losses.append(np.mean(valid_losses))\n",
    "                \n",
    "            # print the results\n",
    "            print(\n",
    "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
    "                end=' '\n",
    "            )\n",
    "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
    "            print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')\n",
    "\n",
    "        return epoch_train_losses, epoch_val_losses\n",
    "        \n",
    "    def evaluate(self):\n",
    "\n",
    "        self.model.eval()\n",
    "        times = [0.5, 1, 1.5]\n",
    "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss = [0,0,0]\n",
    "            length = 0\n",
    "            for x,y in self.testing_DataLoader:\n",
    "               \n",
    "                x,y = x.float().to(self.device), y.float().to(self.device)\n",
    "                out = self.model(x)\n",
    "                 \n",
    "                for i in range(3):\n",
    "                    loss[i] = (x[:,i,:,:] - y[:,i,:,:]).abs().sum(axis = 1).sum(axis = 1).sum()\n",
    "\n",
    "                length+= x.shape[0]*x.shape[-1]\n",
    "               \n",
    "\n",
    "        print(f'L1 for 0.5 seconds: {loss[0]/length:.4f}; for 1.0 second: {loss[1]/length:.4f}, for 1.5 seconds: {loss[2]/length:.4f}',end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07e03ddf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07e03ddf",
    "outputId": "2f009708-8b08-4480-fe6d-0ee55a6f422d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 1/20 [00:01<00:31,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 01/20 LOSS: 2.0999 VAL-LOSS: 1.7095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [00:03<00:29,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 02/20 LOSS: 1.4740 VAL-LOSS: 1.2714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [00:04<00:28,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 03/20 LOSS: 1.1576 VAL-LOSS: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [00:06<00:26,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 04/20 LOSS: 0.8982 VAL-LOSS: 0.7943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [00:08<00:24,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 05/20 LOSS: 0.7439 VAL-LOSS: 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [00:09<00:23,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 06/20 LOSS: 0.6547 VAL-LOSS: 0.6139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████                                                      | 7/20 [00:11<00:21,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 07/20 LOSS: 0.5934 VAL-LOSS: 0.5696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [00:13<00:19,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 08/20 LOSS: 0.5463 VAL-LOSS: 0.5307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [00:14<00:18,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 09/20 LOSS: 0.5117 VAL-LOSS: 0.4984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [00:16<00:16,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10/20 LOSS: 0.4811 VAL-LOSS: 0.4673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [00:18<00:15,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11/20 LOSS: 0.4584 VAL-LOSS: 0.4492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [00:20<00:13,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12/20 LOSS: 0.4387 VAL-LOSS: 0.4395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [00:21<00:12,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13/20 LOSS: 0.4240 VAL-LOSS: 0.4189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [00:23<00:10,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14/20 LOSS: 0.4074 VAL-LOSS: 0.4055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [00:25<00:08,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15/20 LOSS: 0.3949 VAL-LOSS: 0.3922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [00:27<00:06,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 16/20 LOSS: 0.3852 VAL-LOSS: 0.3829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [00:28<00:05,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17/20 LOSS: 0.3777 VAL-LOSS: 0.3695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [00:30<00:03,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 18/20 LOSS: 0.3712 VAL-LOSS: 0.3628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [00:32<00:01,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19/20 LOSS: 0.3595 VAL-LOSS: 0.3541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:34<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20/20 LOSS: 0.3530 VAL-LOSS: 0.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "model = ParticleModel(device, set_size = 5, input_size = 5, \n",
    "                 fau1_out = 8, gamma1_out = 16, fau2_out = 16, gamma2_out = 32,\n",
    "                 hidden_dim = 32, output_shape = 2, horizon_length= 3).to(device)\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "TrainingProcedure = Trainer(model, \n",
    "                            device, \n",
    "                            criterion, #torch.nn.BCELoss(),\n",
    "                            optimizer,\n",
    "                            train_dataloader,\n",
    "                            valid_dataloader,\n",
    "                            test_dataloader,\n",
    "                            epochs = 20)\n",
    "\n",
    "\n",
    "\n",
    "train_loss, val_loss = TrainingProcedure.run_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "vMNfTR4COjmI",
   "metadata": {
    "id": "vMNfTR4COjmI"
   },
   "outputs": [],
   "source": [
    "def evaluate(self):\n",
    "\n",
    "    self.model.eval()\n",
    "    times = [0.5, 1, 1.5]\n",
    "    time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss = [0,0,0]\n",
    "        length = 0\n",
    "        for x,y in self.testing_DataLoader:\n",
    "               \n",
    "            x,y = x.float().to(self.device), y.float().to(self.device)\n",
    "            out = self.model(x)\n",
    "                 \n",
    "            for i in range(3):\n",
    "                loss[i] = (out[:,i,:,:] - y[:,i,:,:]).abs().sum(axis = 1).sum(axis = 1).sum()\n",
    "\n",
    "            length+= x.shape[0]*x.shape[2]\n",
    "               \n",
    "\n",
    "    print(f'L1 for 0.5 seconds: {loss[0]/length:.4f}; for 1.0 second: {loss[1]/length:.4f}, for 1.5 seconds: {loss[2]/length:.4f}',end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ZrMeWNkqP6HP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrMeWNkqP6HP",
    "outputId": "1a9665d6-2091-4553-d4a2-58bc69fcc31e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 for 0.5 seconds: 0.0040; for 1.0 second: 0.0063, for 1.5 seconds: 0.0093 "
     ]
    }
   ],
   "source": [
    "evaluate(TrainingProcedure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h4Q2sjnLMF1x",
   "metadata": {
    "id": "h4Q2sjnLMF1x"
   },
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "Qg9_y_vwQWYT",
   "metadata": {
    "id": "Qg9_y_vwQWYT"
   },
   "outputs": [],
   "source": [
    "# (simulation id, parameters (x, y, c, v_x, v_y), particle id)\n",
    "def predict(x, time):\n",
    "    predictions = torch.cat([x[:,0,:]+ time*x[:,-2,:], x[:,1,:] + time*x[:,-1,:]], dim = 1)\n",
    "    return predictions.view((x.shape[0], -1, x.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4h5qIZPJMFW1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4h5qIZPJMFW1",
    "outputId": "1cd458f6-a15f-471a-8abc-81d564aeb619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 for 0.5 seconds: 0.0016; for 1.0 second: 0.0042, for 1.5 seconds: 0.0069 "
     ]
    }
   ],
   "source": [
    "times = [0.5, 1, 1.5]\n",
    "loss = [0,0,0]\n",
    "length = 0\n",
    "for x,y in test_dataloader:    \n",
    "    for i in range(3):\n",
    "        pred = predict(x, times[i])\n",
    "        loss[i] = (pred - y[:,i,:,:]).abs().sum(axis = 1).sum(axis = 1).sum()\n",
    "    length+= x.shape[0]*x.shape[2]\n",
    "\n",
    "print(f'L1 for 0.5 seconds: {loss[0]/length:.4f}; for 1.0 second: {loss[1]/length:.4f}, for 1.5 seconds: {loss[2]/length:.4f}',end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2896299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.6875"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0187/0.0016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6fa4a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.190476190476191"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0218/0.0042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1360570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6666666666666665"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 0.0253/0.0069 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {
    "id": "d5fb3b29"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed539a8",
   "metadata": {
    "id": "5ed539a8"
   },
   "source": [
    "### Some ideas on the experimental part:\n",
    "\n",
    "* Try various aggregation functions: Mean, Pooling (Max and Min)\n",
    "* Compare different target time as an input\n",
    "* Check different losses\n",
    "* Regularization to the embeddings (linear layers) (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fa1b4",
   "metadata": {
    "id": "bf5fa1b4"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280031f",
   "metadata": {
    "id": "2280031f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "750db0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786abddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "a2_RNN.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "b001d610a241339cc3b7988a7f6c804c70cb4dbbf032519cbfea0d67797e8b2b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
