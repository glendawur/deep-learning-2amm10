{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d32f8d18",
      "metadata": {
        "id": "d32f8d18"
      },
      "source": [
        "# Group Number:\n",
        "\n",
        "# Student 1: Ryan Meghoe\n",
        "\n",
        "# Student 2: Nikita Jain\n",
        "\n",
        "# Student 3: Andrei Rykov"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faec2056",
      "metadata": {
        "id": "faec2056"
      },
      "source": [
        "# Downloading Data and Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7d0580a5",
      "metadata": {
        "id": "7d0580a5"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import requests\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b0756591",
      "metadata": {
        "id": "b0756591"
      },
      "outputs": [],
      "source": [
        "def load_zip(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    zipf = ZipFile(io.BytesIO(response.content))\n",
        "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
        "\n",
        "def load_array(zipfile, fn):\n",
        "    return np.load(io.BytesIO(zipfile[fn]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bb77a4be",
      "metadata": {
        "id": "bb77a4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes of the training data:\n",
            "\n",
            "positions: (10000, 4, 2, 5)\n",
            "velocities: (10000, 1, 2, 5)\n",
            "charges: (10000, 5, 1)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell loads the training, validation or test data as numpy arrays,\n",
        "with the positions, initial velocities and charge data of the particles.\n",
        "\n",
        "The position arrays are shaped as\n",
        "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
        "\n",
        "The initial velocity arrays are shaped as\n",
        "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
        "\n",
        "The charge arrays are shaped as [simulation id, particle id, 1]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
        "\n",
        "features = ['positions', 'velocities', 'charges']\n",
        "    \n",
        "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
        "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
        "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
        "\n",
        "print('Shapes of the training data:\\n')\n",
        "print(f'positions: {positions_train.shape}')\n",
        "print(f'velocities: {velocities_train.shape}')\n",
        "print(f'charges: {charges_train.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c3ea4cb",
      "metadata": {
        "id": "1c3ea4cb"
      },
      "outputs": [],
      "source": [
        "print('An example of retrieving data from the arrays:\\n\\n')\n",
        "\n",
        "sim_idx = 42\n",
        "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
        "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
        "particle_idx = 3  # corresponds to particle with index 3\n",
        "\n",
        "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
        "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
        "c = charges_train[sim_idx, particle_idx, 0] \n",
        "\n",
        "print(\n",
        "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a3438a",
      "metadata": {
        "id": "10a3438a"
      },
      "outputs": [],
      "source": [
        "print('Overview of no. datapoints:\\n')\n",
        "\n",
        "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9106543",
      "metadata": {
        "id": "f9106543"
      },
      "outputs": [],
      "source": [
        "def plot_example(pos, vel):\n",
        "\n",
        "    fig = plt.figure()\n",
        "    axes = plt.gca()\n",
        "    axes.set_xlim([-5., 5.])\n",
        "    axes.set_ylim([-5., 5.])\n",
        "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
        "    for i in range(pos.shape[-1]):\n",
        "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
        "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
        "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
        "    fig.set_size_inches(7, 7)\n",
        "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
        "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
        "    plt.plot([], [], 'd', color='black', label='initial position')\n",
        "    plt.plot([], [], 'x', color='black', label='final position')\n",
        "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28681a6",
      "metadata": {
        "id": "d28681a6"
      },
      "outputs": [],
      "source": [
        "random_idx = np.random.randint(0, 10000)\n",
        "plot_example(positions_train[random_idx], velocities_train[random_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "059b633c",
      "metadata": {
        "id": "059b633c"
      },
      "source": [
        "# Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e6ecb529",
      "metadata": {
        "id": "e6ecb529"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "X_train = torch.cat((torch.tensor(positions_train[:,0,:,:]), torch.tensor(charges_train).squeeze(-1).unsqueeze(1)), dim=1)\n",
        "X_train = torch.cat((X_train, torch.tensor(velocities_train).squeeze(1)), dim=1) # shape: (simulation id, parameters (x, y, c, v_x, v_y), particle id)\n",
        "y_train = torch.tensor(positions_train[:,1:,:,:]) # shape: (simulation id, time (0.5, 1, 1.5), (x, y), particle id)\n",
        "\n",
        "X_valid = torch.cat((torch.tensor(positions_valid[:,0,:,:]), torch.tensor(charges_valid).squeeze(-1).unsqueeze(1)), dim=1)\n",
        "X_valid = torch.cat((X_valid, torch.tensor(velocities_valid).squeeze(1)), dim=1)\n",
        "y_valid = torch.tensor(positions_valid[:,1:,:,:])\n",
        "\n",
        "X_test = torch.cat((torch.tensor(positions_test[:,0,:,:]), torch.tensor(charges_test).squeeze(-1).unsqueeze(1)), dim=1)\n",
        "X_test = torch.cat((X_test, torch.tensor(velocities_test).squeeze(1)), dim=1)\n",
        "y_test = torch.tensor(positions_test[:,1:,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "f8633eb8",
      "metadata": {
        "id": "f8633eb8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "valid_dataset = TensorDataset(X_valid, y_valid)\n",
        "test_dataset = TensorDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "0a99a32b",
      "metadata": {
        "id": "0a99a32b"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18b2874d",
      "metadata": {
        "id": "18b2874d"
      },
      "source": [
        "# Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "66774050",
      "metadata": {
        "id": "66774050"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ParticleModel(torch.nn.Module):\n",
        "    def __init__(self, set_size: int = 5, input_size: int = 5, \n",
        "                 fau1_out: int = 32, gamma1_out: int = 32, fau2_out: int = 32, gamma2_out: int = 2):\n",
        "        super(ParticleModel, self).__init__()\n",
        "        # first iteration \n",
        "        # layer 1\n",
        "        # input target (x_t, y_t, c_t, v_t) + neighbour (x_n, y_n, c_n, v_n) + edge (distance(t, n)) \n",
        "        # as the result input for first layer is x + x + 1 = 2x + 1 (8 + 1 in our case)\n",
        "        self.fau_iteration1 = nn.Sequential(nn.Linear(input_size*2 + 1, fau1_out),\n",
        "                                            nn.ReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 2\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_1 + time\n",
        "        self.gamma_iteration1 = nn.Sequential(nn.Linear(fau1_out+input_size+1, gamma1_out),\n",
        "                                              nn.ReLU())\n",
        "        self.embedding_size = (set_size, gamma1_out)\n",
        "\n",
        "        # second iteration \n",
        "        # layer 3\n",
        "        # input target (embedding from layer 1) + neigbour (embedding from layer 1) + edge (distance(t, n))\n",
        "        self.fau_iteration2 = nn.Sequential(nn.Linear(gamma1_out*2 + 1, fau2_out),\n",
        "                                            nn.ReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 4\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_3 + time\n",
        "        self.gamma_iteration2 = nn.Sequential(nn.Linear(fau2_out + gamma1_out + 1, gamma2_out))\n",
        "        self.output_size = (set_size, gamma2_out)\n",
        "\n",
        "    \n",
        "    def forward_iteration1(self, particle_set, distances, target_time: float = 2.):\n",
        "        embedding = torch.zeros((particle_set.shape[0], self.embedding_size[0], self.embedding_size[1]))\n",
        "        \n",
        "        for i in range(particle_set.shape[1]):\n",
        "            # concatenate the neighborhood\n",
        "            x = torch.cat([particle_set[:,i].reshape((16, 1, 5)).repeat((1, particle_set.shape[1] - 1, 1)),\n",
        "                           particle_set[:, list(set(range(particle_set.shape[1])).difference({i}))],\n",
        "                           distances[:, i, list(set(range(particle_set.shape[1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                   particle_set.shape[1]-1,1))],\n",
        "                          2)\n",
        "\n",
        "\n",
        "            x = self.fau_iteration1(x)\n",
        "\n",
        "            # aggregation function\n",
        "            # mean as a placeholder for now\n",
        "            x = x.mean(axis = 1)\n",
        "            # concatenate \n",
        "            x = torch.cat([particle_set[:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1),\n",
        "                           torch.Tensor([target_time]).repeat((particle_set.shape[0])).view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            embedding[:,i] = self.gamma_iteration1(x).view(embedding[:,i].shape)\n",
        "        return embedding\n",
        "\n",
        "    def forward_iteration2(self, particle_set, distances, target_time: float = 2.):\n",
        "        embedding = torch.zeros((particle_set.shape[0], self.output_size[0], self.output_size[1]))\n",
        "        for i in range(particle_set.shape[1]):\n",
        "            # concatenate the neighborhood\n",
        "            x = torch.cat([particle_set[:,i].reshape((particle_set.shape[0], 1, particle_set.shape[2])).repeat((1, particle_set.shape[1] - 1, 1)),\n",
        "                           particle_set[:, list(set(range(particle_set.shape[1])).difference({i}))],\n",
        "                           distances[:, i, list(set(range(particle_set.shape[1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                   particle_set.shape[1]-1,1))],\n",
        "                          2)\n",
        "\n",
        "            x = self.fau_iteration2(x)\n",
        "\n",
        "            # aggregation function\n",
        "            # mean as a placeholder for now\n",
        "            x = x.mean(axis = 1)\n",
        "\n",
        "            \n",
        "            # concatenate \n",
        "            x = torch.cat([particle_set[:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1),\n",
        "                           torch.Tensor([target_time]).repeat((particle_set.shape[0])).view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)    \n",
        "\n",
        "            embedding[:,i] = self.gamma_iteration2(x).view(embedding[:,i].shape)\n",
        "        return embedding\n",
        "\n",
        "    def forward(self, particle_set, target_time: float = 2.):\n",
        "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set], dim=0)\n",
        "        p1 = self.forward_iteration1(particle_set = particle_set, distances = distances, target_time=target_time)\n",
        "        out = self.forward_iteration2(particle_set=p1, distances=distances, target_time=target_time)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dea70d73",
      "metadata": {
        "id": "dea70d73"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af520ae",
      "metadata": {
        "id": "3af520ae"
      },
      "outputs": [],
      "source": [
        "# train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e95af5f9",
      "metadata": {
        "id": "e95af5f9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e03ddf",
      "metadata": {
        "id": "07e03ddf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d5fb3b29",
      "metadata": {
        "id": "d5fb3b29"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ed539a8",
      "metadata": {},
      "source": [
        "### Some ideas on the experimental part:\n",
        "\n",
        "* Try various aggregation functions: Mean, Pooling (Max and Min)\n",
        "* Compare different target time as an input\n",
        "* Check different losses\n",
        "* Regularization to the embeddings (linear layers) (?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf5fa1b4",
      "metadata": {
        "id": "bf5fa1b4"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2280031f",
      "metadata": {
        "id": "2280031f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a8240f1",
      "metadata": {
        "id": "3a8240f1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "a2_skeleton.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b001d610a241339cc3b7988a7f6c804c70cb4dbbf032519cbfea0d67797e8b2b"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
