{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d32f8d18",
      "metadata": {
        "id": "d32f8d18"
      },
      "source": [
        "# Group Number:\n",
        "\n",
        "# Student 1: Ryan Meghoe\n",
        "\n",
        "# Student 2: Nikita Jain\n",
        "\n",
        "# Student 3: Andrei Rykov"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faec2056",
      "metadata": {
        "id": "faec2056"
      },
      "source": [
        "# Downloading Data and Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7d0580a5",
      "metadata": {
        "id": "7d0580a5"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import requests\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b0756591",
      "metadata": {
        "id": "b0756591"
      },
      "outputs": [],
      "source": [
        "def load_zip(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    zipf = ZipFile(io.BytesIO(response.content))\n",
        "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
        "\n",
        "def load_array(zipfile, fn):\n",
        "    return np.load(io.BytesIO(zipfile[fn]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bb77a4be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb77a4be",
        "outputId": "709f5ba3-89e2-4d00-dec3-a61c777c4e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of the training data:\n",
            "\n",
            "positions: (10000, 4, 2, 5)\n",
            "velocities: (10000, 1, 2, 5)\n",
            "charges: (10000, 5, 1)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell loads the training, validation or test data as numpy arrays,\n",
        "with the positions, initial velocities and charge data of the particles.\n",
        "\n",
        "The position arrays are shaped as\n",
        "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
        "\n",
        "The initial velocity arrays are shaped as\n",
        "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
        "\n",
        "The charge arrays are shaped as [simulation id, particle id, 1]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
        "\n",
        "features = ['positions', 'velocities', 'charges']\n",
        "    \n",
        "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
        "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
        "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
        "\n",
        "print('Shapes of the training data:\\n')\n",
        "print(f'positions: {positions_train.shape}')\n",
        "print(f'velocities: {velocities_train.shape}')\n",
        "print(f'charges: {charges_train.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1c3ea4cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c3ea4cb",
        "outputId": "276125ce-2246-4ff4-e8fa-0befa892ceca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An example of retrieving data from the arrays:\n",
            "\n",
            "\n",
            "In simulation 42 of the training set, particle 3 with charge -1.0 had coordinates [ 2.05159559 -1.46130851].\n",
            "The initial velocity of this particle was [ 0.28402364 -0.24784824].\n"
          ]
        }
      ],
      "source": [
        "print('An example of retrieving data from the arrays:\\n\\n')\n",
        "\n",
        "sim_idx = 42\n",
        "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
        "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
        "particle_idx = 3  # corresponds to particle with index 3\n",
        "\n",
        "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
        "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
        "c = charges_train[sim_idx, particle_idx, 0] \n",
        "\n",
        "print(\n",
        "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "10a3438a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10a3438a",
        "outputId": "9bb70b84-c8ef-4a49-f4b0-6a8af182084d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overview of no. datapoints:\n",
            "\n",
            "10000 train, 2000 validation, 2000 test simulations\n"
          ]
        }
      ],
      "source": [
        "print('Overview of no. datapoints:\\n')\n",
        "\n",
        "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f9106543",
      "metadata": {
        "id": "f9106543"
      },
      "outputs": [],
      "source": [
        "def plot_example(pos, vel):\n",
        "\n",
        "    fig = plt.figure()\n",
        "    axes = plt.gca()\n",
        "    axes.set_xlim([-5., 5.])\n",
        "    axes.set_ylim([-5., 5.])\n",
        "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
        "    for i in range(pos.shape[-1]):\n",
        "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
        "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
        "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
        "    fig.set_size_inches(7, 7)\n",
        "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
        "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
        "    plt.plot([], [], 'd', color='black', label='initial position')\n",
        "    plt.plot([], [], 'x', color='black', label='final position')\n",
        "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d28681a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "d28681a6",
        "outputId": "b071f957-4e72-4f47-bc8f-797738fad547"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "random_idx = np.random.randint(0, 10000)\n",
        "plot_example(positions_train[random_idx], velocities_train[random_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "059b633c",
      "metadata": {
        "id": "059b633c"
      },
      "source": [
        "# Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e6ecb529",
      "metadata": {
        "id": "e6ecb529"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "X_train = torch.cat((torch.tensor(positions_train[:,0,:,:]), torch.tensor(charges_train).squeeze(-1).unsqueeze(1)), dim=1)\n",
        "X_train = torch.cat((X_train, torch.tensor(velocities_train).squeeze(1)), dim=1) # shape: (simulation id, parameters (x, y, c, v_x, v_y), particle id)\n",
        "y_train = torch.tensor(positions_train[:,1:,:,:]) # shape: (simulation id, time (0.5, 1, 1.5), (x, y), particle id)\n",
        "\n",
        "X_valid = torch.cat((torch.tensor(positions_valid[:,0,:,:]), torch.tensor(charges_valid).squeeze(-1).unsqueeze(1)), dim=1)\n",
        "X_valid = torch.cat((X_valid, torch.tensor(velocities_valid).squeeze(1)), dim=1)\n",
        "y_valid = torch.tensor(positions_valid[:,1:,:,:])\n",
        "\n",
        "X_test = torch.cat((torch.tensor(positions_test[:,0,:,:]), torch.tensor(charges_test).squeeze(-1).unsqueeze(1)), dim=1)\n",
        "X_test = torch.cat((X_test, torch.tensor(velocities_test).squeeze(1)), dim=1)\n",
        "y_test = torch.tensor(positions_test[:,1:,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f8633eb8",
      "metadata": {
        "id": "f8633eb8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "valid_dataset = TensorDataset(X_valid, y_valid)\n",
        "test_dataset = TensorDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0a99a32b",
      "metadata": {
        "id": "0a99a32b"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1\n",
        "\n",
        "The GraphNN-like model that makes predictions based on the embedding of the set. For each timestamp we train a separate model in this section. "
      ],
      "metadata": {
        "id": "blkK-lVfx0SK"
      },
      "id": "blkK-lVfx0SK"
    },
    {
      "cell_type": "markdown",
      "id": "18b2874d",
      "metadata": {
        "id": "18b2874d"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "66774050",
      "metadata": {
        "id": "66774050"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ParticleModel(torch.nn.Module):\n",
        "    def __init__(self, set_size: int = 5, input_size: int = 5, \n",
        "                 fau1_out: int = 16, gamma1_out: int = 32, fau2_out: int = 32, gamma2_out: int = 32, output_size: int = 2, device: torch.device = torch.device('cpu')):\n",
        "        super(ParticleModel, self).__init__()\n",
        "        \n",
        "        #### Getting Graph Embedding\n",
        "        \n",
        "        # first iteration \n",
        "        # layer 1\n",
        "        # input target (x_t, y_t, c_t, v_t) + neighbour (x_n, y_n, c_n, v_n) + edge (distance(t, n)) \n",
        "        # as the result input for first layer is x + x + 1 = 2x + 1 (8 + 1 in our case)\n",
        "        self.fau_iteration1 = nn.Sequential(nn.Linear(input_size*2 + 1, fau1_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 2\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_1 \n",
        "        self.gamma_iteration1 = nn.Sequential(nn.Linear(fau1_out+input_size, gamma1_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        self.embedding_size = gamma1_out\n",
        "\n",
        "        # second iteration \n",
        "        # layer 3\n",
        "        # input target (embedding from layer 1) + neigbour (embedding from layer 1) + edge (distance(t, n))\n",
        "        self.fau_iteration2 = nn.Sequential(nn.Linear(gamma1_out*2 + 1, fau2_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 4\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_3 \n",
        "        self.gamma_iteration2 = nn.Sequential(nn.Linear(fau2_out + gamma1_out, gamma2_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        self.output_size = gamma2_out\n",
        "        self.device = device\n",
        "        self.prediction_size = output_size\n",
        "        self.final_layer = nn.Sequential(nn.Linear(gamma2_out*set_size, output_size*set_size))\n",
        "\n",
        "    \n",
        "    def forward_iteration1(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[1], self.embedding_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration1(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.max(axis = 1).values\n",
        "\n",
        "            # concatenate \n",
        "            # x of shape (batch_size, 1, num_features+fau_output)\n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            \n",
        "            embeddings[:,i] = self.gamma_iteration1(x).view(particle_set.shape[0], -1)\n",
        "        # for convenicence, swap axes when return\n",
        "        return embeddings.swapaxes(1,2)\n",
        "\n",
        "    def forward_iteration2(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[2], self.output_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration2(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.max(axis = 1).values\n",
        "\n",
        "            # concatenate the neighborhood and \n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            embeddings[:,i] = self.gamma_iteration2(x).view(particle_set.shape[0], -1)\n",
        "        return embeddings\n",
        "\n",
        "    def forward(self, particle_set):\n",
        "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set.swapaxes(1,2)], dim=0).to(self.device)\n",
        "        inner_emedding = self.forward_iteration1(particle_set = particle_set, distances = distances).to(self.device)\n",
        "        embedding = self.forward_iteration2(particle_set = inner_emedding, distances = distances)\n",
        "        \n",
        "        prediction = self.final_layer(embedding.view(embedding.shape[0], -1))\n",
        "\n",
        "        return prediction.view(embedding.shape[0], self.prediction_size, -1) # (particle_set.shape[0], 5, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dea70d73",
      "metadata": {
        "id": "dea70d73"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "e95af5f9",
      "metadata": {
        "id": "e95af5f9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "class ParticleDistanceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "      The loss to calculate mean distance between predicted location of particle of each set.\n",
        "      By defaul, Euclidean distance is set\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, norm: float = 2):\n",
        "        super(ParticleDistanceLoss, self).__init__()\n",
        "        self.norm = norm\n",
        "\n",
        "    def forward(self, input_set, target_set):\n",
        "        \"\"\"\n",
        "            (batch_size, coordinates, set_size)\n",
        "        \"\"\"\n",
        "        return (input_set - target_set).norm(p = self.norm, dim = 1).mean(axis = 1).mean()\n",
        "        \n",
        "        \n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self,\n",
        "                 model: torch.nn.Module,\n",
        "                 device: torch.device,\n",
        "                 criterion: torch.nn.Module,\n",
        "                 optimizer: torch.optim.Optimizer,\n",
        "                 training_DataLoader: torch.utils.data.Dataset,\n",
        "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
        "                 testing_DataLoader: torch.utils.data.Dataset ,\n",
        "                 epochs: int\n",
        "                 ):\n",
        "        \n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.training_DataLoader = training_DataLoader\n",
        "        self.validation_DataLoader = validation_DataLoader\n",
        "        self.testing_DataLoader = testing_DataLoader\n",
        "        self.device = device\n",
        "        self.epochs = epochs\n",
        "\n",
        "\n",
        "    def run_trainer(self, target_time):\n",
        "\n",
        "        epoch_train_losses = []\n",
        "        epoch_val_losses = []\n",
        "\n",
        "        times = [0.5, 1, 1.5]\n",
        "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
        "        for epoch in tqdm(range(self.epochs)):\n",
        "                 \n",
        "\n",
        "            self.model.train()  # train mode\n",
        "\n",
        "            train_losses=[]\n",
        "            \n",
        "            correct = 0\n",
        "            length = 0\n",
        "            for x, y in self.training_DataLoader:\n",
        "\n",
        "                A, B = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
        "\n",
        "                self.optimizer.zero_grad()  # zerograd the parameters\n",
        "\n",
        "                loss = 0\n",
        "                out = self.model(A)  # one forward pass\n",
        "                loss += self.criterion(out, B[:,time_to_ind[target_time]])  # calculate loss\n",
        "                \n",
        "                loss_value = loss.item()\n",
        "                train_losses.append(loss_value)\n",
        "                 \n",
        "                loss.backward()  # one backward pass\n",
        "                self.optimizer.step()  # update the parameters\n",
        "            \n",
        "            epoch_train_losses.append(np.mean(train_losses))\n",
        "            self.model.eval()  # evaluation mode\n",
        "            valid_losses = []  # accumulate the losses here\n",
        "\n",
        "            correct = 0\n",
        "            length = 0\n",
        "            for x,  y in self.validation_DataLoader:\n",
        "\n",
        "                A,B = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    loss = 0\n",
        "                    \n",
        "                    out = self.model(A)  # one forward pass\n",
        "                    loss += self.criterion(out, B[:,time_to_ind[target_time]])  # calculate loss\n",
        "                 \n",
        "                    loss_value = loss.item()\n",
        "                    valid_losses.append(loss_value)\n",
        "\n",
        "            epoch_val_losses.append(np.mean(valid_losses))\n",
        "                \n",
        "            # print the results\n",
        "            print(\n",
        "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
        "                end=' '\n",
        "            )\n",
        "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
        "            print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')\n",
        "\n",
        "        return epoch_train_losses, epoch_val_losses\n",
        "        \n",
        "    def evaluate(self, target_time):\n",
        "\n",
        "        self.model.eval()\n",
        "        times = [0.5, 1, 1.5]\n",
        "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loss = []\n",
        "            length = 0\n",
        "            for x,y in self.testing_DataLoader:\n",
        "                \n",
        "                A, B = x.float().to(self.device), y.float().to(self.device)\n",
        "                out = self.model(A)\n",
        "                loss.append(self.criterion(out, B[:,time_to_ind[target_time]]))\n",
        "        print(f'Error: {np.mean(loss):.4f} for target time {target_time}',end=' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "d9bPfkmpEqnT"
      },
      "id": "d9bPfkmpEqnT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with max pooling"
      ],
      "metadata": {
        "id": "O3jtlEzZEwTE"
      },
      "id": "O3jtlEzZEwTE"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "07e03ddf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07e03ddf",
        "outputId": "53ff3afb-6f7a-435a-ccbf-306999bf00e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:02<00:38,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 01/20 LOSS: 0.5841 VAL-LOSS: 0.2566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:04<00:36,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 02/20 LOSS: 0.2414 VAL-LOSS: 0.2716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:06<00:34,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 03/20 LOSS: 0.2219 VAL-LOSS: 0.1926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:08<00:33,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 04/20 LOSS: 0.1945 VAL-LOSS: 0.1860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:10<00:30,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 05/20 LOSS: 0.1828 VAL-LOSS: 0.2198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:12<00:29,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 06/20 LOSS: 0.1814 VAL-LOSS: 0.1693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:14<00:27,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 07/20 LOSS: 0.1715 VAL-LOSS: 0.1742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:16<00:25,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 08/20 LOSS: 0.1744 VAL-LOSS: 0.1689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:18<00:22,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 09/20 LOSS: 0.1655 VAL-LOSS: 0.1621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:21<00:22,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 10/20 LOSS: 0.1647 VAL-LOSS: 0.1669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:23<00:19,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 11/20 LOSS: 0.1628 VAL-LOSS: 0.1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:25<00:17,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 12/20 LOSS: 0.1597 VAL-LOSS: 0.1628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:27<00:14,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 13/20 LOSS: 0.1598 VAL-LOSS: 0.1663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:29<00:12,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 14/20 LOSS: 0.1596 VAL-LOSS: 0.1679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:31<00:10,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 15/20 LOSS: 0.1568 VAL-LOSS: 0.1695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:34<00:09,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 16/20 LOSS: 0.1563 VAL-LOSS: 0.1651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:36<00:06,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 17/20 LOSS: 0.1532 VAL-LOSS: 0.1567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:39<00:04,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 18/20 LOSS: 0.1530 VAL-LOSS: 0.1496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:42<00:02,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 19/20 LOSS: 0.1510 VAL-LOSS: 0.1672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:44<00:00,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 20/20 LOSS: 0.1528 VAL-LOSS: 0.1529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 0.1558 "
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "model = ParticleModel(device = device).to(device)\n",
        "criterion = ParticleDistanceLoss(norm=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "TrainingProcedure = Trainer(model, \n",
        "                            device, \n",
        "                            criterion, \n",
        "                            optimizer,\n",
        "                            train_dataloader,\n",
        "                            valid_dataloader,\n",
        "                            test_dataloader,\n",
        "                            epochs = 20)\n",
        "\n",
        "train_loss, val_loss = TrainingProcedure.run_trainer(target_time=0.5)\n",
        "TrainingProcedure.evaluate(target_time=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "e0f24a09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0f24a09",
        "outputId": "772c9a7d-7100-4693-a46b-cdcec564f862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:02<00:40,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 01/20 LOSS: 0.7574 VAL-LOSS: 0.4170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:04<00:37,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 02/20 LOSS: 0.4039 VAL-LOSS: 0.4254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:06<00:35,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 03/20 LOSS: 0.3630 VAL-LOSS: 0.3407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:08<00:33,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 04/20 LOSS: 0.3400 VAL-LOSS: 0.3230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:10<00:31,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 05/20 LOSS: 0.3281 VAL-LOSS: 0.3271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:12<00:29,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 06/20 LOSS: 0.3213 VAL-LOSS: 0.3151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:14<00:27,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 07/20 LOSS: 0.3138 VAL-LOSS: 0.3376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:16<00:25,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 08/20 LOSS: 0.3117 VAL-LOSS: 0.3034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:19<00:26,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 09/20 LOSS: 0.3030 VAL-LOSS: 0.3155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:22<00:23,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 10/20 LOSS: 0.3011 VAL-LOSS: 0.3011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:24<00:20,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 11/20 LOSS: 0.2933 VAL-LOSS: 0.2966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:26<00:17,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 12/20 LOSS: 0.2896 VAL-LOSS: 0.2902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:28<00:15,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 13/20 LOSS: 0.2876 VAL-LOSS: 0.2839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:31<00:14,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 14/20 LOSS: 0.2810 VAL-LOSS: 0.2585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:33<00:11,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 15/20 LOSS: 0.2757 VAL-LOSS: 0.2622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:35<00:09,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 16/20 LOSS: 0.2675 VAL-LOSS: 0.2640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:38<00:07,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 17/20 LOSS: 0.2655 VAL-LOSS: 0.2591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:40<00:04,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 18/20 LOSS: 0.2641 VAL-LOSS: 0.2657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:42<00:02,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 19/20 LOSS: 0.2621 VAL-LOSS: 0.2665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:44<00:00,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 20/20 LOSS: 0.2560 VAL-LOSS: 0.2566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 0.2641 "
          ]
        }
      ],
      "source": [
        "model = ParticleModel(device = device).to(device)\n",
        "criterion = ParticleDistanceLoss(norm=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "TrainingProcedure = Trainer(model, \n",
        "                            device, \n",
        "                            criterion, \n",
        "                            optimizer,\n",
        "                            train_dataloader,\n",
        "                            valid_dataloader,\n",
        "                            test_dataloader,\n",
        "                            epochs = 20)\n",
        "\n",
        "train_loss, val_loss = TrainingProcedure.run_trainer(target_time=1)\n",
        "TrainingProcedure.evaluate(target_time=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "f4f81969",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4f81969",
        "outputId": "590b4283-886f-477e-8818-9b838c1fbea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:02<00:40,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 01/20 LOSS: 0.9779 VAL-LOSS: 0.5888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:04<00:38,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 02/20 LOSS: 0.5174 VAL-LOSS: 0.5361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:06<00:39,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 03/20 LOSS: 0.4793 VAL-LOSS: 0.4753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:10<00:43,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 04/20 LOSS: 0.4591 VAL-LOSS: 0.4479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:13<00:45,  3.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 05/20 LOSS: 0.4446 VAL-LOSS: 0.4522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:19<00:53,  3.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 06/20 LOSS: 0.4367 VAL-LOSS: 0.4370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:22<00:46,  3.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 07/20 LOSS: 0.4205 VAL-LOSS: 0.4334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:24<00:37,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 08/20 LOSS: 0.4131 VAL-LOSS: 0.4124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:26<00:31,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 09/20 LOSS: 0.4050 VAL-LOSS: 0.4181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:28<00:25,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 10/20 LOSS: 0.3932 VAL-LOSS: 0.3855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:30<00:22,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 11/20 LOSS: 0.3806 VAL-LOSS: 0.3836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:32<00:18,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 12/20 LOSS: 0.3739 VAL-LOSS: 0.3816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:34<00:15,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 13/20 LOSS: 0.3679 VAL-LOSS: 0.3610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:37<00:13,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 14/20 LOSS: 0.3584 VAL-LOSS: 0.3465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:39<00:11,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 15/20 LOSS: 0.3534 VAL-LOSS: 0.3607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:41<00:08,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 16/20 LOSS: 0.3515 VAL-LOSS: 0.3632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:43<00:06,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 17/20 LOSS: 0.3495 VAL-LOSS: 0.3696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:46<00:04,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 18/20 LOSS: 0.3469 VAL-LOSS: 0.3480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:49<00:02,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 19/20 LOSS: 0.3477 VAL-LOSS: 0.3518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:51<00:00,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 20/20 LOSS: 0.3395 VAL-LOSS: 0.3385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 0.3471 "
          ]
        }
      ],
      "source": [
        "model = ParticleModel(device = device).to(device)\n",
        "criterion = ParticleDistanceLoss(norm=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "TrainingProcedure = Trainer(model, \n",
        "                            device, \n",
        "                            criterion, \n",
        "                            optimizer,\n",
        "                            train_dataloader,\n",
        "                            valid_dataloader,\n",
        "                            test_dataloader,\n",
        "                            epochs = 20)\n",
        "\n",
        "train_loss, val_loss = TrainingProcedure.run_trainer(target_time=1.5)\n",
        "TrainingProcedure.evaluate(target_time=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5cf8f64",
      "metadata": {
        "id": "b5cf8f64"
      },
      "source": [
        "### Linear interpolation results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "5c619cd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c619cd3",
        "outputId": "c3d56479-27a9-4e0f-c7f2-8440cffeec66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of mean distance (Eudclidean) for 0.5 seconds: 0.1682; for 1.0 second: 0.3932, for 1.5 seconds: 0.6314 "
          ]
        }
      ],
      "source": [
        "# (simulation id, time (0.5, 1, 1.5), (x, y), particle id)\n",
        "# (simulation id, parameters (x, y, c, v_x, v_y), particle id)\n",
        "\n",
        "def predict(x, time):\n",
        "    predictions = torch.cat([x[:,0,:]+ time*x[:,-2,:], x[:,1,:] + time*x[:,-1,:]], dim = 1)\n",
        "    return predictions.view((x.shape[0], -1, x.shape[-1]))\n",
        "\n",
        "loss_f = ParticleDistanceLoss(norm = 2)\n",
        "\n",
        "times = [0.5, 1, 1.5]\n",
        "time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
        "loss = [[],[],[]]\n",
        "for x,y in test_dataloader:\n",
        "    for time in times:                    \n",
        "        A, B = x.float(), y.float()\n",
        "        out = predict(A, time)\n",
        "        loss[time_to_ind[time]].append(loss_f(out, B[:,time_to_ind[time]]))\n",
        "\n",
        "print(f'Mean of mean distance (Eudclidean) for 0.5 seconds: {np.mean(loss[0]):.4f}; for 1.0 second: {np.mean(loss[1]):.4f}, for 1.5 seconds: {np.mean(loss[2]):.4f}',end=' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with Mean Pooling"
      ],
      "metadata": {
        "id": "qt1bd2y9C760"
      },
      "id": "qt1bd2y9C760"
    },
    {
      "cell_type": "code",
      "source": [
        "class ParticleModel(torch.nn.Module):\n",
        "    def __init__(self, set_size: int = 5, input_size: int = 5, \n",
        "                 fau1_out: int = 16, gamma1_out: int = 32, fau2_out: int = 32, gamma2_out: int = 32, output_size: int = 2, device: torch.device = torch.device('cpu')):\n",
        "        super(ParticleModel, self).__init__()\n",
        "        \n",
        "        #### Getting Graph Embedding\n",
        "        \n",
        "        # first iteration \n",
        "        # layer 1\n",
        "        # input target (x_t, y_t, c_t, v_t) + neighbour (x_n, y_n, c_n, v_n) + edge (distance(t, n)) \n",
        "        # as the result input for first layer is x + x + 1 = 2x + 1 (8 + 1 in our case)\n",
        "        self.fau_iteration1 = nn.Sequential(nn.Linear(input_size*2 + 1, fau1_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 2\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_1 \n",
        "        self.gamma_iteration1 = nn.Sequential(nn.Linear(fau1_out+input_size, gamma1_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        self.embedding_size = gamma1_out\n",
        "\n",
        "        # second iteration \n",
        "        # layer 3\n",
        "        # input target (embedding from layer 1) + neigbour (embedding from layer 1) + edge (distance(t, n))\n",
        "        self.fau_iteration2 = nn.Sequential(nn.Linear(gamma1_out*2 + 1, fau2_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 4\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_3 \n",
        "        self.gamma_iteration2 = nn.Sequential(nn.Linear(fau2_out + gamma1_out, gamma2_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        self.output_size = gamma2_out\n",
        "        self.device = device\n",
        "        self.prediction_size = output_size\n",
        "        self.final_layer = nn.Sequential(nn.Linear(gamma2_out*set_size, output_size*set_size))\n",
        "\n",
        "    \n",
        "    def forward_iteration1(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[1], self.embedding_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration1(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.mean(axis = 1)\n",
        "\n",
        "            # concatenate \n",
        "            # x of shape (batch_size, 1, num_features+fau_output)\n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            \n",
        "            embeddings[:,i] = self.gamma_iteration1(x).view(particle_set.shape[0], -1)\n",
        "        # for convenicence, swap axes when return\n",
        "        return embeddings.swapaxes(1,2)\n",
        "\n",
        "    def forward_iteration2(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[2], self.output_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration2(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.mean(axis = 1)\n",
        "\n",
        "            # concatenate the neighborhood and \n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            embeddings[:,i] = self.gamma_iteration2(x).view(particle_set.shape[0], -1)\n",
        "        return embeddings\n",
        "\n",
        "    def forward(self, particle_set):\n",
        "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set.swapaxes(1,2)], dim=0).to(self.device)\n",
        "        inner_emedding = self.forward_iteration1(particle_set = particle_set, distances = distances).to(self.device)\n",
        "        embedding = self.forward_iteration2(particle_set = inner_emedding, distances = distances)\n",
        "        \n",
        "        prediction = self.final_layer(embedding.view(embedding.shape[0], -1))\n",
        "\n",
        "        return prediction.view(embedding.shape[0], self.prediction_size, -1) # (particle_set.shape[0], 5, 2)"
      ],
      "metadata": {
        "id": "Kc9LFwZICSx1"
      },
      "id": "Kc9LFwZICSx1",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times = [0.5, 1, 1.5]\n",
        "time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
        "\n",
        "for time in times:\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "    else:\n",
        "        device=torch.device('cpu')\n",
        "\n",
        "    model = ParticleModel(device = device).to(device)\n",
        "    criterion = ParticleDistanceLoss(norm=2)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    TrainingProcedure = Trainer(model, \n",
        "                                device, \n",
        "                                criterion, \n",
        "                                optimizer,\n",
        "                                train_dataloader,\n",
        "                                valid_dataloader,\n",
        "                                test_dataloader,\n",
        "                                epochs = 20)\n",
        "\n",
        "    train_loss, val_loss = TrainingProcedure.run_trainer(target_time=time)\n",
        "    TrainingProcedure.evaluate(target_time=time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwZsl0pDChJt",
        "outputId": "594870eb-edbc-43f2-fafb-2cca22bf59f4"
      },
      "id": "ZwZsl0pDChJt",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:02<00:38,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 01/20 LOSS: 0.5408 VAL-LOSS: 0.2548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:04<00:36,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 02/20 LOSS: 0.2278 VAL-LOSS: 0.2168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:05<00:33,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 03/20 LOSS: 0.2030 VAL-LOSS: 0.1901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:07<00:31,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 04/20 LOSS: 0.1887 VAL-LOSS: 0.1950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:09<00:29,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 05/20 LOSS: 0.1837 VAL-LOSS: 0.1716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:11<00:27,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 06/20 LOSS: 0.1760 VAL-LOSS: 0.1985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:13<00:25,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 07/20 LOSS: 0.1757 VAL-LOSS: 0.1737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:15<00:23,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 08/20 LOSS: 0.1736 VAL-LOSS: 0.1863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:17<00:21,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 09/20 LOSS: 0.1705 VAL-LOSS: 0.1723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:19<00:19,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 10/20 LOSS: 0.1696 VAL-LOSS: 0.1871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:21<00:17,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 11/20 LOSS: 0.1709 VAL-LOSS: 0.1595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:23<00:16,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 12/20 LOSS: 0.1663 VAL-LOSS: 0.1837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:25<00:13,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 13/20 LOSS: 0.1679 VAL-LOSS: 0.1836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:27<00:11,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 14/20 LOSS: 0.1649 VAL-LOSS: 0.1563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:29<00:09,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 15/20 LOSS: 0.1648 VAL-LOSS: 0.1630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:31<00:07,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 16/20 LOSS: 0.1648 VAL-LOSS: 0.1704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:33<00:05,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 17/20 LOSS: 0.1651 VAL-LOSS: 0.1801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:35<00:03,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 18/20 LOSS: 0.1623 VAL-LOSS: 0.1781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:37<00:01,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 19/20 LOSS: 0.1608 VAL-LOSS: 0.1519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:39<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 20/20 LOSS: 0.1569 VAL-LOSS: 0.1558\n",
            "Error: 0.1591 for target time 0.5 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:02<00:38,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 01/20 LOSS: 0.7293 VAL-LOSS: 0.4300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:04<00:36,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 02/20 LOSS: 0.4023 VAL-LOSS: 0.3737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:06<00:34,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 03/20 LOSS: 0.3513 VAL-LOSS: 0.3524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:08<00:32,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 04/20 LOSS: 0.3376 VAL-LOSS: 0.3355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:10<00:29,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 05/20 LOSS: 0.3318 VAL-LOSS: 0.3349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:12<00:27,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 06/20 LOSS: 0.3248 VAL-LOSS: 0.3191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:14<00:26,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 07/20 LOSS: 0.3146 VAL-LOSS: 0.3214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:16<00:24,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 08/20 LOSS: 0.3145 VAL-LOSS: 0.3186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:18<00:22,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 09/20 LOSS: 0.3098 VAL-LOSS: 0.3069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:20<00:19,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 10/20 LOSS: 0.3082 VAL-LOSS: 0.3103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:22<00:17,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 11/20 LOSS: 0.3022 VAL-LOSS: 0.3212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:24<00:15,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 12/20 LOSS: 0.3045 VAL-LOSS: 0.2877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:26<00:14,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 13/20 LOSS: 0.2994 VAL-LOSS: 0.3045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:28<00:12,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 14/20 LOSS: 0.2956 VAL-LOSS: 0.2915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:30<00:10,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 15/20 LOSS: 0.2892 VAL-LOSS: 0.2936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:32<00:08,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 16/20 LOSS: 0.2885 VAL-LOSS: 0.2819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:34<00:06,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 17/20 LOSS: 0.2859 VAL-LOSS: 0.2871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:36<00:04,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 18/20 LOSS: 0.2799 VAL-LOSS: 0.2794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:38<00:02,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 19/20 LOSS: 0.2772 VAL-LOSS: 0.2846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:40<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 20/20 LOSS: 0.2737 VAL-LOSS: 0.2693\n",
            "Error: 0.2766 for target time 1 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:01<00:37,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 01/20 LOSS: 0.9329 VAL-LOSS: 0.5707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:03<00:35,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 02/20 LOSS: 0.5407 VAL-LOSS: 0.5211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:05<00:33,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 03/20 LOSS: 0.5021 VAL-LOSS: 0.5183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:07<00:31,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 04/20 LOSS: 0.4818 VAL-LOSS: 0.4719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:09<00:29,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 05/20 LOSS: 0.4746 VAL-LOSS: 0.4573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:11<00:27,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 06/20 LOSS: 0.4638 VAL-LOSS: 0.4763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:13<00:25,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 07/20 LOSS: 0.4514 VAL-LOSS: 0.4665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:15<00:23,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 08/20 LOSS: 0.4447 VAL-LOSS: 0.4427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:17<00:21,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 09/20 LOSS: 0.4385 VAL-LOSS: 0.4313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:19<00:19,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 10/20 LOSS: 0.4277 VAL-LOSS: 0.4697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:21<00:17,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 11/20 LOSS: 0.4284 VAL-LOSS: 0.4302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:23<00:15,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 12/20 LOSS: 0.4173 VAL-LOSS: 0.4454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:25<00:13,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 13/20 LOSS: 0.4152 VAL-LOSS: 0.4289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:27<00:11,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 14/20 LOSS: 0.4057 VAL-LOSS: 0.4157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:29<00:09,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 15/20 LOSS: 0.4002 VAL-LOSS: 0.4038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:31<00:07,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 16/20 LOSS: 0.3958 VAL-LOSS: 0.3947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:33<00:05,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 17/20 LOSS: 0.3896 VAL-LOSS: 0.3925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:35<00:03,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 18/20 LOSS: 0.3820 VAL-LOSS: 0.4133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:37<00:01,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 19/20 LOSS: 0.3781 VAL-LOSS: 0.3833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:39<00:00,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 20/20 LOSS: 0.3773 VAL-LOSS: 0.3861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 0.3930 for target time 1.5 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results comparison"
      ],
      "metadata": {
        "id": "GEZhrF4wEDI0"
      },
      "id": "GEZhrF4wEDI0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison\n",
        "\n",
        "**Mean pooling**:\n",
        "\n",
        "Mean distance (Eudclidean) for 0.5 seconds: 0.1591; for 1.0 second: 0.2766, for 1.5 seconds: 0.3930\n",
        "\n",
        "**Max pooling**: \n",
        "\n",
        "Mean distance (Eudclidean) for 0.5 seconds: 0.1558; for 1.0 second: 0.2641, for 1.5 seconds: 0.3471\n",
        "\n",
        "**Linear interpolation**:\n",
        "\n",
        "Mean distance (Eudclidean) for 0.5 seconds: 0.1682; for 1.0 second: 0.3932, for 1.5 seconds: 0.6314 \n",
        "\n",
        "As the result, simple model provides more precise prediction as the time goe than a linear interpolation by the formula $ x^t_i = x^0_i + v^0_i*t $, where $x$ is the coordinate and $v$ is velocity."
      ],
      "metadata": {
        "id": "ZVQNHIGCD0ME"
      },
      "id": "ZVQNHIGCD0ME"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2\n",
        "\n",
        "The model with GraphNN-like embedding extraction followed by the LSTM. That model is considered to make prediction based on previous prediction and thus creates sequence of predictions for next **n** timestamps with step-size of 0.5 seconds."
      ],
      "metadata": {
        "id": "12U9ShwSGi9a"
      },
      "id": "12U9ShwSGi9a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model implementation"
      ],
      "metadata": {
        "id": "w3kzTcgQHHdg"
      },
      "id": "w3kzTcgQHHdg"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ParticleModelLSTM(torch.nn.Module):\n",
        "    def __init__(self, set_size: int = 5, input_size: int = 5, \n",
        "                 fau1_out: int = 16, gamma1_out: int = 32, fau2_out: int = 32, gamma2_out: int = 32, output_size: int = 2,\n",
        "                 hidden_dim: int = 32, horizon_length: int = 3,\n",
        "                 device: torch.device = torch.device('cpu')):\n",
        "        super(ParticleModelLSTM, self).__init__()\n",
        "        \n",
        "        #### Getting Graph Embedding\n",
        "        \n",
        "        # first iteration \n",
        "        # layer 1\n",
        "        # input target (x_t, y_t, c_t, v_t) + neighbour (x_n, y_n, c_n, v_n) + edge (distance(t, n)) \n",
        "        # as the result input for first layer is x + x + 1 = 2x + 1 (8 + 1 in our case)\n",
        "        self.fau_iteration1 = nn.Sequential(nn.Linear(input_size*2 + 1, fau1_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 2\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_1 \n",
        "        self.gamma_iteration1 = nn.Sequential(nn.Linear(fau1_out+input_size, gamma1_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        self.embedding_size = gamma1_out\n",
        "\n",
        "        # second iteration \n",
        "        # layer 3\n",
        "        # input target (embedding from layer 1) + neigbour (embedding from layer 1) + edge (distance(t, n))\n",
        "        self.fau_iteration2 = nn.Sequential(nn.Linear(gamma1_out*2 + 1, fau2_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 4\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_3 \n",
        "        self.gamma_iteration2 = nn.Sequential(nn.Linear(fau2_out + gamma1_out, gamma2_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        \n",
        "        #self.final_layer = nn.Sequential(nn.Linear(gamma2_out*set_size, output_size*set_size))\n",
        "\n",
        "         # Recurrent Part\n",
        "        self.rnn = nn.LSTM(gamma2_out*set_size, hidden_dim, num_layers = 1, batch_first = True)\n",
        "        \n",
        "        # Fully connected layer after RNN output, to learn more complex relations\n",
        "        self.final = nn.Linear(hidden_dim, output_size*set_size)\n",
        "\n",
        "\n",
        "        # auxiliary variables \n",
        "        self.output_size = gamma2_out\n",
        "        self.device = device\n",
        "        self.prediction_size = output_size\n",
        "        self.horizon_length = horizon_length\n",
        "        self.set_size = set_size\n",
        "\n",
        "    \n",
        "    def forward_iteration1(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[1], self.embedding_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration1(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.max(axis = 1).values\n",
        "\n",
        "            # concatenate \n",
        "            # x of shape (batch_size, 1, num_features+fau_output)\n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            \n",
        "            embeddings[:,i] = self.gamma_iteration1(x).view(particle_set.shape[0], -1)\n",
        "        # for convenicence, swap axes when return\n",
        "        return embeddings.swapaxes(1,2)\n",
        "\n",
        "    def forward_iteration2(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[2], self.output_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration2(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.max(axis = 1).values\n",
        "\n",
        "            # concatenate the neighborhood and \n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            embeddings[:,i] = self.gamma_iteration2(x).view(particle_set.shape[0], -1)\n",
        "        return embeddings\n",
        "\n",
        "    def forward(self, particle_set):\n",
        "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set.swapaxes(1,2)], dim=0).to(self.device)\n",
        "        inner_emedding = self.forward_iteration1(particle_set = particle_set, distances = distances).to(self.device)\n",
        "        embedding = self.forward_iteration2(particle_set = inner_emedding, distances = distances)\n",
        "        zeros = torch.zeros((embedding.shape[0], self.horizon_length, embedding.shape[-1]*self.set_size)).to(self.device) \n",
        "        #(batch_size, 1, embedding_dim)\n",
        "        rnn_input = torch.cat([embedding.view((embedding.shape[0], 1, -1)), zeros], dim=1)\n",
        "        # Input: (Batch size, L (sequence length), input_shape)\n",
        "        # rnn_output: (Batch size, L (sequence length), output_shape)\n",
        "        rnn_output, rnn_state = self.rnn(rnn_input)\n",
        "\n",
        "        output = self.final(rnn_output[:,1:,:])\n",
        "\n",
        "        return output.view((output.shape[0], self.horizon_length, self.prediction_size, self.set_size))"
      ],
      "metadata": {
        "id": "8UP7RPOBG7R8"
      },
      "id": "8UP7RPOBG7R8",
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "o09IWs0mKmaA"
      },
      "id": "o09IWs0mKmaA"
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self,\n",
        "                 model: torch.nn.Module,\n",
        "                 device: torch.device,\n",
        "                 criterion: torch.nn.Module,\n",
        "                 optimizer: torch.optim.Optimizer,\n",
        "                 training_DataLoader: torch.utils.data.Dataset,\n",
        "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
        "                 testing_DataLoader: torch.utils.data.Dataset ,\n",
        "                 epochs: int\n",
        "                 ):\n",
        "        \n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.training_DataLoader = training_DataLoader\n",
        "        self.validation_DataLoader = validation_DataLoader\n",
        "        self.testing_DataLoader = testing_DataLoader\n",
        "        self.device = device\n",
        "        self.epochs = epochs\n",
        "\n",
        "\n",
        "    def run_trainer(self):\n",
        "\n",
        "        epoch_train_losses = []\n",
        "        epoch_val_losses = []\n",
        "\n",
        "        times = [0.5, 1, 1.5]\n",
        "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
        "        for epoch in tqdm(range(self.epochs)):\n",
        "                 \n",
        "\n",
        "            self.model.train()  # train mode\n",
        "\n",
        "            train_losses=[]\n",
        "            \n",
        "            for x, y in self.training_DataLoader:\n",
        "\n",
        "                x, y = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
        "\n",
        "                self.optimizer.zero_grad()  # zerograd the parameters\n",
        "\n",
        "                out = self.model(x)\n",
        "                loss = 0\n",
        "                for i in range(3):\n",
        "                    loss += self.criterion(y[:,i], out[:,i])\n",
        "                \n",
        "                loss_value = loss.item()/3\n",
        "                train_losses.append(loss_value)\n",
        "                 \n",
        "                loss.backward()  # one backward pass\n",
        "                self.optimizer.step()  # update the parameters\n",
        "            \n",
        "            epoch_train_losses.append(np.mean(train_losses))\n",
        "            self.model.eval()  # evaluation mode\n",
        "            valid_losses = []  # accumulate the losses here\n",
        "\n",
        "            correct = 0\n",
        "            length = 0\n",
        "            for x,  y in self.validation_DataLoader:\n",
        "\n",
        "                x,y = x.float().to(self.device), y.float().to(self.device) # send to device (GPU or CPU)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    out = self.model(x)\n",
        "                    loss = 0\n",
        "                    for i in range(3):\n",
        "                        loss += self.criterion(y[:,i], out[:,i])\n",
        "                    \n",
        "                    loss_value = loss.item()/3\n",
        "                    valid_losses.append(loss_value)\n",
        "\n",
        "            epoch_val_losses.append(np.mean(valid_losses))\n",
        "                \n",
        "            # print the results\n",
        "            print(\n",
        "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
        "                end=' '\n",
        "            )\n",
        "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
        "            print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')\n",
        "\n",
        "        return epoch_train_losses, epoch_val_losses\n",
        "        \n",
        "    def evaluate(self):\n",
        "\n",
        "        self.model.eval()\n",
        "        times = [0.5, 1, 1.5]\n",
        "        time_to_ind = {0.5:0, 1:1, 1.5:2}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loss_separate = [[],[],[]]\n",
        "            overall_loss = []\n",
        "            for x,y in self.testing_DataLoader:\n",
        "\n",
        "                x,y = x.float().to(self.device), y.float().to(self.device)\n",
        "                out = self.model(x)\n",
        "\n",
        "                loss = 0\n",
        "                for i in range(3):\n",
        "                    loss_separate[i].append(self.criterion(y[:,i], out[:,i]).item())\n",
        "                    loss+=loss_separate[i][-1]\n",
        "                overall_loss.append(loss/3)\n",
        "\n",
        "        print(f'Error for 0.5 seconds: {np.mean(loss_separate[0]):.4f}; for 1.0 second: {np.mean(loss_separate[1]):.4f}, for 1.5 seconds: {np.mean(loss_separate[2]):.4f}')\n",
        "        print(f'Error over all time (training like): {np.mean(overall_loss):.4f}')"
      ],
      "metadata": {
        "id": "fx-o9sRWIl0d"
      },
      "id": "fx-o9sRWIl0d",
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "lCqMj7lwMvQv"
      },
      "id": "lCqMj7lwMvQv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with max pooling"
      ],
      "metadata": {
        "id": "I_Z-Jfm4M1gy"
      },
      "id": "I_Z-Jfm4M1gy"
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "model = ParticleModelLSTM(device = device).to(device)\n",
        "criterion = ParticleDistanceLoss(norm=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "TrainingProcedure = Trainer(model, \n",
        "                            device, \n",
        "                            criterion, \n",
        "                            optimizer,\n",
        "                            train_dataloader,\n",
        "                            valid_dataloader,\n",
        "                            test_dataloader,\n",
        "                            epochs = 20)\n",
        "\n",
        "train_loss, val_loss = TrainingProcedure.run_trainer()\n",
        "TrainingProcedure.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZFQz0CzM2nE",
        "outputId": "0c18ed1f-6d41-49ef-a4f5-3a7ecff5c9f8"
      },
      "id": "2ZFQz0CzM2nE",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:02<00:50,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 01/20 LOSS: 1.7652 VAL-LOSS: 0.8620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:05<00:47,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 02/20 LOSS: 0.7043 VAL-LOSS: 0.6117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:07<00:44,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 03/20 LOSS: 0.5594 VAL-LOSS: 0.5188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:10<00:41,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 04/20 LOSS: 0.4992 VAL-LOSS: 0.4887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:12<00:38,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 05/20 LOSS: 0.4644 VAL-LOSS: 0.4862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:15<00:36,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 06/20 LOSS: 0.4506 VAL-LOSS: 0.4815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:18<00:33,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 07/20 LOSS: 0.4385 VAL-LOSS: 0.4363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:20<00:31,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 08/20 LOSS: 0.4241 VAL-LOSS: 0.4126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:23<00:28,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 09/20 LOSS: 0.4140 VAL-LOSS: 0.4274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:25<00:25,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 10/20 LOSS: 0.4062 VAL-LOSS: 0.4057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:28<00:23,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 11/20 LOSS: 0.3967 VAL-LOSS: 0.3998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:31<00:20,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 12/20 LOSS: 0.3871 VAL-LOSS: 0.3998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:33<00:18,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 13/20 LOSS: 0.3808 VAL-LOSS: 0.3933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:36<00:15,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 14/20 LOSS: 0.3781 VAL-LOSS: 0.3781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:38<00:13,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 15/20 LOSS: 0.3690 VAL-LOSS: 0.3769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:41<00:10,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 16/20 LOSS: 0.3682 VAL-LOSS: 0.3776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:44<00:07,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 17/20 LOSS: 0.3699 VAL-LOSS: 0.3714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:46<00:05,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 18/20 LOSS: 0.3607 VAL-LOSS: 0.3550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:49<00:02,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 19/20 LOSS: 0.3618 VAL-LOSS: 0.3717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:52<00:00,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 20/20 LOSS: 0.3595 VAL-LOSS: 0.3682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error for 0.5 seconds: 0.2818; for 1.0 second: 0.3414, for 1.5 seconds: 0.4955 Error over all time (training like): 0.3729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with mean pooling"
      ],
      "metadata": {
        "id": "-KQsWYrUP6hm"
      },
      "id": "-KQsWYrUP6hm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code changes"
      ],
      "metadata": {
        "id": "T_QraFA7P_G3"
      },
      "id": "T_QraFA7P_G3"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ParticleModelLSTM(torch.nn.Module):\n",
        "    def __init__(self, set_size: int = 5, input_size: int = 5, \n",
        "                 fau1_out: int = 16, gamma1_out: int = 32, fau2_out: int = 32, gamma2_out: int = 32, output_size: int = 2,\n",
        "                 hidden_dim: int = 32, horizon_length: int = 3,\n",
        "                 device: torch.device = torch.device('cpu')):\n",
        "        super(ParticleModelLSTM, self).__init__()\n",
        "        \n",
        "        #### Getting Graph Embedding\n",
        "        \n",
        "        # first iteration \n",
        "        # layer 1\n",
        "        # input target (x_t, y_t, c_t, v_t) + neighbour (x_n, y_n, c_n, v_n) + edge (distance(t, n)) \n",
        "        # as the result input for first layer is x + x + 1 = 2x + 1 (8 + 1 in our case)\n",
        "        self.fau_iteration1 = nn.Sequential(nn.Linear(input_size*2 + 1, fau1_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 2\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_1 \n",
        "        self.gamma_iteration1 = nn.Sequential(nn.Linear(fau1_out+input_size, gamma1_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        self.embedding_size = gamma1_out\n",
        "\n",
        "        # second iteration \n",
        "        # layer 3\n",
        "        # input target (embedding from layer 1) + neigbour (embedding from layer 1) + edge (distance(t, n))\n",
        "        self.fau_iteration2 = nn.Sequential(nn.Linear(gamma1_out*2 + 1, fau2_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 4\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_3 \n",
        "        self.gamma_iteration2 = nn.Sequential(nn.Linear(fau2_out + gamma1_out, gamma2_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        \n",
        "        #self.final_layer = nn.Sequential(nn.Linear(gamma2_out*set_size, output_size*set_size))\n",
        "\n",
        "         # Recurrent Part\n",
        "        self.rnn = nn.LSTM(gamma2_out*set_size, hidden_dim, num_layers = 1, batch_first = True)\n",
        "        \n",
        "        # Fully connected layer after RNN output, to learn more complex relations\n",
        "        self.final = nn.Linear(hidden_dim, output_size*set_size)\n",
        "\n",
        "\n",
        "        # auxiliary variables \n",
        "        self.output_size = gamma2_out\n",
        "        self.device = device\n",
        "        self.prediction_size = output_size\n",
        "        self.horizon_length = horizon_length\n",
        "        self.set_size = set_size\n",
        "\n",
        "    \n",
        "    def forward_iteration1(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[1], self.embedding_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration1(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.mean(axis = 1)\n",
        "\n",
        "            # concatenate \n",
        "            # x of shape (batch_size, 1, num_features+fau_output)\n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            \n",
        "            embeddings[:,i] = self.gamma_iteration1(x).view(particle_set.shape[0], -1)\n",
        "        # for convenicence, swap axes when return\n",
        "        return embeddings.swapaxes(1,2)\n",
        "\n",
        "    def forward_iteration2(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[2], self.output_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration2(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.mean(axis = 1)\n",
        "\n",
        "            # concatenate the neighborhood and \n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            embeddings[:,i] = self.gamma_iteration2(x).view(particle_set.shape[0], -1)\n",
        "        return embeddings\n",
        "\n",
        "    def forward(self, particle_set):\n",
        "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set.swapaxes(1,2)], dim=0).to(self.device)\n",
        "        inner_emedding = self.forward_iteration1(particle_set = particle_set, distances = distances).to(self.device)\n",
        "        embedding = self.forward_iteration2(particle_set = inner_emedding, distances = distances)\n",
        "        zeros = torch.zeros((embedding.shape[0], self.horizon_length, embedding.shape[-1]*self.set_size)).to(self.device) \n",
        "        #(batch_size, 1, embedding_dim)\n",
        "        rnn_input = torch.cat([embedding.view((embedding.shape[0], 1, -1)), zeros], dim=1)\n",
        "        # Input: (Batch size, L (sequence length), input_shape)\n",
        "        # rnn_output: (Batch size, L (sequence length), output_shape)\n",
        "        rnn_output, rnn_state = self.rnn(rnn_input)\n",
        "\n",
        "        output = self.final(rnn_output[:,1:,:])\n",
        "\n",
        "        return output.view((output.shape[0], self.horizon_length, self.prediction_size, self.set_size))"
      ],
      "metadata": {
        "id": "4eP047vsP-d9"
      },
      "id": "4eP047vsP-d9",
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### results"
      ],
      "metadata": {
        "id": "s0EbjfQ0QDFs"
      },
      "id": "s0EbjfQ0QDFs"
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "model = ParticleModelLSTM(device = device).to(device)\n",
        "criterion = ParticleDistanceLoss(norm=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "TrainingProcedure = Trainer(model, \n",
        "                            device, \n",
        "                            criterion, \n",
        "                            optimizer,\n",
        "                            train_dataloader,\n",
        "                            valid_dataloader,\n",
        "                            test_dataloader,\n",
        "                            epochs = 20)\n",
        "\n",
        "train_loss, val_loss = TrainingProcedure.run_trainer()\n",
        "TrainingProcedure.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBzu6uW3P8rA",
        "outputId": "5850936a-d9c6-4f9f-9c42-32b75f9d450e"
      },
      "id": "PBzu6uW3P8rA",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:03<01:01,  3.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 01/20 LOSS: 1.7670 VAL-LOSS: 0.9098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:05<00:51,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 02/20 LOSS: 0.7038 VAL-LOSS: 0.6243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:08<00:46,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 03/20 LOSS: 0.5671 VAL-LOSS: 0.5297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:11<00:43,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 04/20 LOSS: 0.5052 VAL-LOSS: 0.4985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:13<00:39,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 05/20 LOSS: 0.4710 VAL-LOSS: 0.4729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:16<00:36,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 06/20 LOSS: 0.4531 VAL-LOSS: 0.4712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:18<00:34,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 07/20 LOSS: 0.4402 VAL-LOSS: 0.4487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:21<00:31,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 08/20 LOSS: 0.4242 VAL-LOSS: 0.4800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:24<00:30,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 09/20 LOSS: 0.4175 VAL-LOSS: 0.4248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:27<00:27,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 10/20 LOSS: 0.4089 VAL-LOSS: 0.4193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:29<00:24,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 11/20 LOSS: 0.3957 VAL-LOSS: 0.4139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:32<00:21,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 12/20 LOSS: 0.3942 VAL-LOSS: 0.4176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:35<00:19,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 13/20 LOSS: 0.3853 VAL-LOSS: 0.4099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:38<00:16,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 14/20 LOSS: 0.3817 VAL-LOSS: 0.3828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:40<00:13,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 15/20 LOSS: 0.3790 VAL-LOSS: 0.3877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:43<00:10,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 16/20 LOSS: 0.3713 VAL-LOSS: 0.3912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:47<00:09,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 17/20 LOSS: 0.3670 VAL-LOSS: 0.3818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:50<00:06,  3.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 18/20 LOSS: 0.3718 VAL-LOSS: 0.3745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:53<00:02,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 19/20 LOSS: 0.3656 VAL-LOSS: 0.3858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:55<00:00,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 20/20 LOSS: 0.3634 VAL-LOSS: 0.3787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error for 0.5 seconds: 0.2857; for 1.0 second: 0.3545, for 1.5 seconds: 0.5149 Error over all time (training like): 0.3851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More LSTM layers (3 layers)"
      ],
      "metadata": {
        "id": "y7mtM7Q4QWPN"
      },
      "id": "y7mtM7Q4QWPN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code changes"
      ],
      "metadata": {
        "id": "Aw9xlcRIQZO2"
      },
      "id": "Aw9xlcRIQZO2"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ParticleModelLSTM(torch.nn.Module):\n",
        "    def __init__(self, set_size: int = 5, input_size: int = 5, \n",
        "                 fau1_out: int = 16, gamma1_out: int = 32, fau2_out: int = 32, gamma2_out: int = 32, output_size: int = 2,\n",
        "                 hidden_dim: int = 32, horizon_length: int = 3,\n",
        "                 device: torch.device = torch.device('cpu')):\n",
        "        super(ParticleModelLSTM, self).__init__()\n",
        "        \n",
        "        #### Getting Graph Embedding\n",
        "        \n",
        "        # first iteration \n",
        "        # layer 1\n",
        "        # input target (x_t, y_t, c_t, v_t) + neighbour (x_n, y_n, c_n, v_n) + edge (distance(t, n)) \n",
        "        # as the result input for first layer is x + x + 1 = 2x + 1 (8 + 1 in our case)\n",
        "        self.fau_iteration1 = nn.Sequential(nn.Linear(input_size*2 + 1, fau1_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 2\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_1 \n",
        "        self.gamma_iteration1 = nn.Sequential(nn.Linear(fau1_out+input_size, gamma1_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        self.embedding_size = gamma1_out\n",
        "\n",
        "        # second iteration \n",
        "        # layer 3\n",
        "        # input target (embedding from layer 1) + neigbour (embedding from layer 1) + edge (distance(t, n))\n",
        "        self.fau_iteration2 = nn.Sequential(nn.Linear(gamma1_out*2 + 1, fau2_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 4\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_3 \n",
        "        self.gamma_iteration2 = nn.Sequential(nn.Linear(fau2_out + gamma1_out, gamma2_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        \n",
        "        #self.final_layer = nn.Sequential(nn.Linear(gamma2_out*set_size, output_size*set_size))\n",
        "\n",
        "         # Recurrent Part\n",
        "        self.rnn = nn.LSTM(gamma2_out*set_size, hidden_dim, num_layers = 3, batch_first = True)\n",
        "        \n",
        "        # Fully connected layer after RNN output, to learn more complex relations\n",
        "        self.final = nn.Linear(hidden_dim, output_size*set_size)\n",
        "\n",
        "\n",
        "        # auxiliary variables \n",
        "        self.output_size = gamma2_out\n",
        "        self.device = device\n",
        "        self.prediction_size = output_size\n",
        "        self.horizon_length = horizon_length\n",
        "        self.set_size = set_size\n",
        "\n",
        "    \n",
        "    def forward_iteration1(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[1], self.embedding_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration1(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.max(axis = 1).values\n",
        "\n",
        "            # concatenate \n",
        "            # x of shape (batch_size, 1, num_features+fau_output)\n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            \n",
        "            embeddings[:,i] = self.gamma_iteration1(x).view(particle_set.shape[0], -1)\n",
        "        # for convenicence, swap axes when return\n",
        "        return embeddings.swapaxes(1,2)\n",
        "\n",
        "    def forward_iteration2(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[2], self.output_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration2(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.max(axis = 1).values\n",
        "\n",
        "            # concatenate the neighborhood and \n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            embeddings[:,i] = self.gamma_iteration2(x).view(particle_set.shape[0], -1)\n",
        "        return embeddings\n",
        "\n",
        "    def forward(self, particle_set):\n",
        "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set.swapaxes(1,2)], dim=0).to(self.device)\n",
        "        inner_emedding = self.forward_iteration1(particle_set = particle_set, distances = distances).to(self.device)\n",
        "        embedding = self.forward_iteration2(particle_set = inner_emedding, distances = distances)\n",
        "        zeros = torch.zeros((embedding.shape[0], self.horizon_length, embedding.shape[-1]*self.set_size)).to(self.device) \n",
        "        #(batch_size, 1, embedding_dim)\n",
        "        rnn_input = torch.cat([embedding.view((embedding.shape[0], 1, -1)), zeros], dim=1)\n",
        "        # Input: (Batch size, L (sequence length), input_shape)\n",
        "        # rnn_output: (Batch size, L (sequence length), output_shape)\n",
        "        rnn_output, rnn_state = self.rnn(rnn_input)\n",
        "\n",
        "        output = self.final(rnn_output[:,1:,:])\n",
        "\n",
        "        return output.view((output.shape[0], self.horizon_length, self.prediction_size, self.set_size))"
      ],
      "metadata": {
        "id": "s4_pQST6QYyl"
      },
      "id": "s4_pQST6QYyl",
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### results"
      ],
      "metadata": {
        "id": "nD_v_TSwQi3k"
      },
      "id": "nD_v_TSwQi3k"
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "model = ParticleModelLSTM(device = device).to(device)\n",
        "criterion = ParticleDistanceLoss(norm=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "TrainingProcedure = Trainer(model, \n",
        "                            device, \n",
        "                            criterion, \n",
        "                            optimizer,\n",
        "                            train_dataloader,\n",
        "                            valid_dataloader,\n",
        "                            test_dataloader,\n",
        "                            epochs = 20)\n",
        "\n",
        "train_loss, val_loss = TrainingProcedure.run_trainer()\n",
        "TrainingProcedure.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-A9_HLsQmhc",
        "outputId": "05a99385-4499-4354-9db6-c9cde1f37383"
      },
      "id": "b-A9_HLsQmhc",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:03<01:02,  3.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 01/20 LOSS: 2.4154 VAL-LOSS: 1.4600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:06<00:58,  3.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 02/20 LOSS: 1.1768 VAL-LOSS: 1.0821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:09<00:54,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 03/20 LOSS: 0.7746 VAL-LOSS: 0.7574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:12<00:50,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 04/20 LOSS: 0.6187 VAL-LOSS: 0.5706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:15<00:47,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 05/20 LOSS: 0.5658 VAL-LOSS: 0.5761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:19<00:44,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 06/20 LOSS: 0.5341 VAL-LOSS: 0.5026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:22<00:41,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 07/20 LOSS: 0.5051 VAL-LOSS: 0.5373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:25<00:37,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 08/20 LOSS: 0.4935 VAL-LOSS: 0.5171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:28<00:34,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 09/20 LOSS: 0.4778 VAL-LOSS: 0.4974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:31<00:31,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 10/20 LOSS: 0.4648 VAL-LOSS: 0.5510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:34<00:28,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 11/20 LOSS: 0.4674 VAL-LOSS: 0.4762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:38<00:25,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 12/20 LOSS: 0.4459 VAL-LOSS: 0.4279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:41<00:22,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 13/20 LOSS: 0.4447 VAL-LOSS: 0.4437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:44<00:19,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 14/20 LOSS: 0.4369 VAL-LOSS: 0.4746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:47<00:15,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 15/20 LOSS: 0.4255 VAL-LOSS: 0.4494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:50<00:12,  3.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 16/20 LOSS: 0.4226 VAL-LOSS: 0.4311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:54<00:09,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 17/20 LOSS: 0.4279 VAL-LOSS: 0.4433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:58<00:06,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 18/20 LOSS: 0.4211 VAL-LOSS: 0.4232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [01:01<00:03,  3.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 19/20 LOSS: 0.4219 VAL-LOSS: 0.4370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:04<00:00,  3.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 20/20 LOSS: 0.4153 VAL-LOSS: 0.4147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error for 0.5 seconds: 0.3063; for 1.0 second: 0.4012, for 1.5 seconds: 0.5621 Error over all time (training like): 0.4232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Embedding Encoding before LSTM"
      ],
      "metadata": {
        "id": "oGXojQo8Q_Qc"
      },
      "id": "oGXojQo8Q_Qc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code changes"
      ],
      "metadata": {
        "id": "36prjWIeRD4h"
      },
      "id": "36prjWIeRD4h"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ParticleModelLSTM(torch.nn.Module):\n",
        "    def __init__(self, set_size: int = 5, input_size: int = 5, \n",
        "                 fau1_out: int = 16, gamma1_out: int = 32, fau2_out: int = 32, gamma2_out: int = 32, output_size: int = 2,\n",
        "                 lstm_input: int = 32, hidden_dim: int = 32, horizon_length: int = 3,\n",
        "                 device: torch.device = torch.device('cpu')):\n",
        "        super(ParticleModelLSTM, self).__init__()\n",
        "        \n",
        "        #### Getting Graph Embedding\n",
        "        \n",
        "        # first iteration \n",
        "        # layer 1\n",
        "        # input target (x_t, y_t, c_t, v_t) + neighbour (x_n, y_n, c_n, v_n) + edge (distance(t, n)) \n",
        "        # as the result input for first layer is x + x + 1 = 2x + 1 (8 + 1 in our case)\n",
        "        self.fau_iteration1 = nn.Sequential(nn.Linear(input_size*2 + 1, fau1_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 2\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_1 \n",
        "        self.gamma_iteration1 = nn.Sequential(nn.Linear(fau1_out+input_size, gamma1_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        self.embedding_size = gamma1_out\n",
        "\n",
        "        # second iteration \n",
        "        # layer 3\n",
        "        # input target (embedding from layer 1) + neigbour (embedding from layer 1) + edge (distance(t, n))\n",
        "        self.fau_iteration2 = nn.Sequential(nn.Linear(gamma1_out*2 + 1, fau2_out),\n",
        "                                            nn.LeakyReLU())\n",
        "        # embeddings are calculated\n",
        "\n",
        "        # layer 4\n",
        "        # input (x_target, y_target, c_target, v_target) + embedding from layer_3 \n",
        "        self.gamma_iteration2 = nn.Sequential(nn.Linear(fau2_out + gamma1_out, gamma2_out),\n",
        "                                              nn.LeakyReLU())\n",
        "        \n",
        "        self.final_embedding_layer = nn.Sequential(nn.Linear(gamma2_out*set_size, lstm_input),\n",
        "                                         nn.LeakyReLU())\n",
        "\n",
        "         # Recurrent Part\n",
        "        self.rnn = nn.LSTM(lstm_input, hidden_dim, num_layers = 1, batch_first = True)\n",
        "        \n",
        "        # Fully connected layer after RNN output, to learn more complex relations\n",
        "        self.final = nn.Linear(hidden_dim, output_size*set_size)\n",
        "\n",
        "\n",
        "        # auxiliary variables \n",
        "        self.output_size = gamma2_out\n",
        "        self.device = device\n",
        "        self.prediction_size = output_size\n",
        "        self.horizon_length = horizon_length\n",
        "        self.set_size = set_size\n",
        "        self.lstm_input = lstm_input\n",
        "\n",
        "    \n",
        "    def forward_iteration1(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[1], self.embedding_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration1(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.max(axis = 1).values\n",
        "\n",
        "            # concatenate \n",
        "            # x of shape (batch_size, 1, num_features+fau_output)\n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            \n",
        "            embeddings[:,i] = self.gamma_iteration1(x).view(particle_set.shape[0], -1)\n",
        "        # for convenicence, swap axes when return\n",
        "        return embeddings.swapaxes(1,2)\n",
        "\n",
        "    def forward_iteration2(self, particle_set, distances):\n",
        "        \"\"\"\n",
        "          particle_set - the matrix of shape (batch_size, num_features, set_size)\n",
        "        \"\"\"\n",
        "        # matrix of shape (batch_size, set_size, embedding_size)\n",
        "        embeddings = torch.zeros((particle_set.shape[0], particle_set.shape[2], self.output_size)).to(self.device)\n",
        "        \n",
        "        #iterate over the particles in the set\n",
        "        for i in range(particle_set.shape[-1]):\n",
        "            # concatenate the neighborhood\n",
        "            \n",
        "            # x of shape (batch_size, set_size - 1, num_features*2 + 1)\n",
        "            x = torch.cat([# duplicate the vector of target particle\n",
        "                           particle_set[:,:,i].reshape((particle_set.shape[0], 1, -1)).repeat((1, particle_set.shape[-1] - 1, 1)),\n",
        "                           # choose vectors of all other particles\n",
        "                           particle_set[:,:, list(set(range(particle_set.shape[-1])).difference({i}))].swapaxes(1,2),\n",
        "                           # choose distances from i-th particle to all other particles\n",
        "                           distances[:, i, list(set(range(particle_set.shape[-1])).difference({i}))].reshape((particle_set.shape[0],\\\n",
        "                                                                                                              particle_set.shape[-1]-1,-1))],\n",
        "                          dim=2)\n",
        "\n",
        "            x = self.fau_iteration2(x)\n",
        "\n",
        "            # aggregation function over dimension = 1 -- the whole neighborhood\n",
        "            x = x.max(axis = 1).values\n",
        "\n",
        "            # concatenate the neighborhood and \n",
        "            x = torch.cat([particle_set[:,:, i].view(particle_set.shape[0], 1, -1),\n",
        "                           x.view(particle_set.shape[0], 1, -1)],\n",
        "                           dim = 2)\n",
        "            embeddings[:,i] = self.gamma_iteration2(x).view(particle_set.shape[0], -1)\n",
        "        return embeddings\n",
        "\n",
        "    def forward(self, particle_set):\n",
        "        distances = torch.stack([torch.cdist(x_i, x_i) for x_i in particle_set.swapaxes(1,2)], dim=0).to(self.device)\n",
        "        inner_emedding = self.forward_iteration1(particle_set = particle_set, distances = distances).to(self.device)\n",
        "        embedding = self.forward_iteration2(particle_set = inner_emedding, distances = distances)\n",
        "\n",
        "        embedding = self.final_embedding_layer(embedding.view((embedding.shape[0], 1, -1)))\n",
        "\n",
        "        zeros = torch.zeros((embedding.shape[0], self.horizon_length, embedding.shape[-1])).to(self.device) \n",
        "        #(batch_size, 1, embedding_dim)\n",
        "        rnn_input = torch.cat([embedding.view((embedding.shape[0], 1, -1)), zeros], dim=1)\n",
        "        # Input: (Batch size, L (sequence length), input_shape)\n",
        "        # rnn_output: (Batch size, L (sequence length), output_shape)\n",
        "        rnn_output, rnn_state = self.rnn(rnn_input)\n",
        "\n",
        "        output = self.final(rnn_output[:,1:,:])\n",
        "\n",
        "        return output.view((output.shape[0], self.horizon_length, self.prediction_size, self.set_size))"
      ],
      "metadata": {
        "id": "OLyMsRNbQ-wF"
      },
      "id": "OLyMsRNbQ-wF",
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### results"
      ],
      "metadata": {
        "id": "VK3IfeG7RFTV"
      },
      "id": "VK3IfeG7RFTV"
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "model = ParticleModelLSTM(device = device).to(device)\n",
        "criterion = ParticleDistanceLoss(norm=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "TrainingProcedure = Trainer(model, \n",
        "                            device, \n",
        "                            criterion, \n",
        "                            optimizer,\n",
        "                            train_dataloader,\n",
        "                            valid_dataloader,\n",
        "                            test_dataloader,\n",
        "                            epochs = 20)\n",
        "\n",
        "train_loss, val_loss = TrainingProcedure.run_trainer()\n",
        "TrainingProcedure.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK3fyTGYRGDL",
        "outputId": "436423a8-177c-45e8-883a-bc3ad625ec25"
      },
      "id": "vK3fyTGYRGDL",
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [00:04<01:21,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 01/20 LOSS: 2.0521 VAL-LOSS: 1.0910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:06<01:00,  3.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 02/20 LOSS: 0.8283 VAL-LOSS: 0.6878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:09<00:51,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 03/20 LOSS: 0.6365 VAL-LOSS: 0.6558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:12<00:46,  2.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 04/20 LOSS: 0.5706 VAL-LOSS: 0.5278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:14<00:42,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 05/20 LOSS: 0.5310 VAL-LOSS: 0.5090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [00:17<00:38,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 06/20 LOSS: 0.5010 VAL-LOSS: 0.4800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [00:20<00:35,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 07/20 LOSS: 0.4903 VAL-LOSS: 0.4846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [00:23<00:32,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 08/20 LOSS: 0.4681 VAL-LOSS: 0.4669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [00:25<00:29,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 09/20 LOSS: 0.4726 VAL-LOSS: 0.4762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [00:28<00:27,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 10/20 LOSS: 0.4559 VAL-LOSS: 0.4423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:31<00:24,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 11/20 LOSS: 0.4494 VAL-LOSS: 0.4462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [00:33<00:21,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 12/20 LOSS: 0.4440 VAL-LOSS: 0.4716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:36<00:18,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 13/20 LOSS: 0.4508 VAL-LOSS: 0.4472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [00:39<00:16,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 14/20 LOSS: 0.4266 VAL-LOSS: 0.4403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:41<00:13,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 15/20 LOSS: 0.4286 VAL-LOSS: 0.4398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [00:44<00:10,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 16/20 LOSS: 0.4233 VAL-LOSS: 0.4215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:47<00:08,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 17/20 LOSS: 0.4230 VAL-LOSS: 0.4562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [00:49<00:05,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 18/20 LOSS: 0.4231 VAL-LOSS: 0.4439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:52<00:02,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 19/20 LOSS: 0.4178 VAL-LOSS: 0.4289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:55<00:00,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 20/20 LOSS: 0.4099 VAL-LOSS: 0.3971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error for 0.5 seconds: 0.2828; for 1.0 second: 0.3716, for 1.5 seconds: 0.5452 Error over all time (training like): 0.3999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eiMjFFLbR0CE"
      },
      "id": "eiMjFFLbR0CE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "faec2056",
        "059b633c",
        "18b2874d",
        "dea70d73",
        "O3jtlEzZEwTE",
        "b5cf8f64",
        "qt1bd2y9C760",
        "w3kzTcgQHHdg",
        "o09IWs0mKmaA",
        "I_Z-Jfm4M1gy",
        "-KQsWYrUP6hm",
        "T_QraFA7P_G3",
        "s0EbjfQ0QDFs",
        "y7mtM7Q4QWPN",
        "Aw9xlcRIQZO2",
        "36prjWIeRD4h",
        "VK3IfeG7RFTV"
      ],
      "name": "Assignment_2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b001d610a241339cc3b7988a7f6c804c70cb4dbbf032519cbfea0d67797e8b2b"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}